08/17/2022 17:06:49 - WARNING - __main__ -   device: cuda, n_gpu: 1
Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
08/17/2022 17:06:56 - INFO - __main__ -   Training/evaluation parameters Namespace(train_data_file='../data/subsets/dataset_size/balanced_0.01/train.csv', output_dir='./saved_models/dataset_size/balanced_0.01', model_type='roberta', block_size=512, eval_data_file='../data/subsets/dataset_size/balanced_0.01/valid.csv', test_data_file='../data/subsets/dataset_size/balanced_0.01/test.csv', model_name='model.bin', model_name_or_path='microsoft/codebert-base', config_name='', use_non_pretrained_model=False, tokenizer_name='microsoft/codebert-base', code_length=256, do_train=True, do_eval=False, do_test=True, evaluate_during_training=True, do_local_explanation=False, reasoning_method=None, train_batch_size=16, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=2e-05, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, seed=123456, epochs=10, effort_at_top_k=0.2, top_k_recall_by_lines=0.01, top_k_recall_by_pred_prob=0.2, do_sorting_by_line_scores=False, do_sorting_by_pred_prob=False, top_k_constant=10, num_attention_heads=12, write_raw_preds=False, use_word_level_tokenizer=False, use_non_pretrained_tokenizer=False, n_gpu=1, device=device(type='cuda'))
load dataset:   0%|          | 0/429 [00:00<?, ?it/s]load dataset:  12%|█▏        | 52/429 [00:00<00:00, 518.89it/s]load dataset:  26%|██▌       | 110/429 [00:00<00:00, 553.82it/s]load dataset:  39%|███▊      | 166/429 [00:00<00:00, 304.83it/s]load dataset:  48%|████▊     | 206/429 [00:00<00:00, 256.69it/s]load dataset:  55%|█████▌    | 238/429 [00:01<00:01, 180.12it/s]load dataset:  62%|██████▏   | 268/429 [00:01<00:00, 197.49it/s]load dataset:  72%|███████▏  | 309/429 [00:01<00:00, 239.07it/s]load dataset:  79%|███████▉  | 339/429 [00:01<00:00, 233.75it/s]load dataset:  90%|█████████ | 388/429 [00:01<00:00, 290.93it/s]load dataset:  98%|█████████▊| 422/429 [00:01<00:00, 262.90it/s]load dataset: 100%|██████████| 429/429 [00:01<00:00, 261.63it/s]
08/17/2022 17:06:58 - INFO - __main__ -   *** Example ***
08/17/2022 17:06:58 - INFO - __main__ -   label: 0
08/17/2022 17:06:58 - INFO - __main__ -   input_tokens: ['<s>', 'int', '_do', '_', 'show', '(', 'FILE', '_*', 'stream', ',', '_const', '_char', '_*', 'path', '_', 'p', ',', '_const', '_struct', '_stat', '_*', 'st', ',', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_a', 'cl', '_', 't', '_a', 'cl', ',', '_a', 'cl', '_', 't', '_d', 'acl', ')', 'Ċ', '{', 'Ċ', 'ĉ', 'struct', '_name', '_', 'list', '_*', 'acl', '_', 'names', '_=', '_get', '_', 'list', '(', 'st', ',', '_a', 'cl', '),', 'Ċ', 'ĉ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_*', 'first', '_', 'acl', '_', 'name', '_=', '_a', 'cl', '_', 'names', ';', 'Ċ', 'ĉ', 'struct', '_name', '_', 'list', '_*', 'd', 'acl', '_', 'names', '_=', '_get', '_', 'list', '(', 'st', ',', '_d', 'acl', '),', 'Ċ', 'ĉ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_*', 'first', '_', 'd', 'acl', '_', 'name', '_=', '_d', 'acl', '_', 'names', ';', 'Ċ', 'ĉ', 'Ċ', 'ĉ', 'int', '_a', 'cl', '_', 'names', '_', 'width', '_=', '_max', '_', 'name', '_', 'length', '(', 'acl', '_', 'names', ');', 'Ċ', 'ĉ', 'int', '_d', 'acl', '_', 'names', '_', 'width', '_=', '_max', '_', 'name', '_', 'length', '(', 'd', 'acl', '_', 'names', ');', 'Ċ', 'ĉ', 'acl', '_', 'entry', '_', 't', '_a', 'cl', '_', 'ent', ';', 'Ċ', 'ĉ', 'acl', '_', 'entry', '_', 't', '_d', 'acl', '_', 'ent', ';', 'Ċ', 'ĉ', 'char', '_a', 'cl', '_', 'mask', '[', 'AC', 'L', '_', 'PER', 'MS', '+', '1', '],', '_d', 'acl', '_', 'mask', '[', 'AC', 'L', '_', 'PER', 'MS', '+', '1', '];', 'Ċ', 'ĉ', 'int', '_ret', ';', 'ĊĊ', 'ĉ', 'names', '_', 'width', '_=', '_8', ';', 'Ċ', 'ĉ', 'if', '_(', 'acl', '_', 'names', '_', 'width', '_>', '_names', '_', 'width', ')', 'Ċ', 'ĉ', 'ĉ', 'names', '_', 'width', '_=', '_a', 'cl', '_', 'names', '_', 'width', ';', 'Ċ', 'ĉ', 'if', '_(', 'd', 'acl', '_', 'names', '_', 'width', '_>', '_names', '_', 'width', ')', 'Ċ', 'ĉ', 'ĉ', 'names', '_', 'width', '_=', '_d', 'acl', '_', 'names', '_', 'width', ';', 'ĊĊ', 'ĉ', 'acl', '_', 'mask', '[', '0', ']', '_=', "_'", '\\', '0', "';", 'Ċ', 'ĉ', 'if', '_(', 'acl', ')', '_{', 'Ċ', 'ĉ', 'ĉ', 'acl', '_', 'mask', '_', 'perm', '_', 'str', '(', 'acl', ',', '_a', 'cl', '_', 'mask', ');', 'Ċ', 'ĉ', 'ĉ', 'ret', '_=', '_a', 'cl', '_', 'get', '_', 'entry', '(', 'acl', ',', '_ACL', '_', 'FIR', 'ST', '_', 'ENT', 'RY', ',', '_&', 'acl', '_', 'ent', ');', 'Ċ', 'ĉ', 'ĉ', 'if', '_(', 'ret', '_==', '_0', ')', 'Ċ', 'ĉ', 'ĉ', 'ĉ', 'acl', '_=', '_NULL', ';', 'Ċ', 'ĉ', 'ĉ', 'if', '_(', 'ret', '_<', '_0', ')', 'Ċ', 'ĉ', 'ĉ', 'ĉ', 'return', '_ret', ';', 'Ċ', 'ĉ', '}', 'Ċ', 'ĉ', 'd', 'acl', '_', 'mask', '[', '0', ']', '_=', "_'", '\\', '0', "';", 'Ċ', 'ĉ', 'if', '_(', 'd', 'acl', ')', '_{', 'Ċ', 'ĉ', 'ĉ', 'acl', '_', 'mask', '_', 'perm', '_', 'str', '(', 'd', 'acl', ',', '_d', 'acl', '_', 'mask', ');', 'Ċ', 'ĉ', 'ĉ', 'ret', '_=', '_a', 'cl', '_', 'get', '_', 'entry', '(', 'd', 'acl', ',', '_ACL', '_', 'FIR', 'ST', '_', 'ENT', 'RY', ',', '_&', 'd', 'acl', '_', 'ent', ');', 'Ċ', 'ĉ', 'ĉ', 'if', '_(', 'ret', '_==', '_0', ')', 'Ċ', 'ĉ', 'ĉ', 'ĉ', 'd', 'acl', '_=', '_NULL', ';', 'Ċ', 'ĉ', 'ĉ', '</s>']
08/17/2022 17:06:58 - INFO - __main__ -   input_ids: 0 2544 109 1215 12005 1640 19572 1009 8656 6 10759 16224 1009 22609 1215 642 6 10759 29916 12377 1009 620 6 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 10 3998 1215 90 10 3998 6 10 3998 1215 90 385 40054 43 50118 45152 50118 50117 25384 766 1215 8458 1009 40054 1215 37815 5457 120 1215 8458 1640 620 6 10 3998 238 50118 50117 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1009 9502 1215 40054 1215 13650 5457 10 3998 1215 37815 131 50118 50117 25384 766 1215 8458 1009 417 40054 1215 37815 5457 120 1215 8458 1640 620 6 385 40054 238 50118 50117 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1009 9502 1215 417 40054 1215 13650 5457 385 40054 1215 37815 131 50118 50117 50118 50117 2544 10 3998 1215 37815 1215 36097 5457 19220 1215 13650 1215 16096 1640 40054 1215 37815 4397 50118 50117 2544 385 40054 1215 37815 1215 36097 5457 19220 1215 13650 1215 16096 1640 417 40054 1215 37815 4397 50118 50117 40054 1215 12595 1215 90 10 3998 1215 1342 131 50118 50117 40054 1215 12595 1215 90 385 40054 1215 1342 131 50118 50117 24262 10 3998 1215 43776 10975 2562 574 1215 21260 6222 2744 134 7479 385 40054 1215 43776 10975 2562 574 1215 21260 6222 2744 134 44082 50118 50117 2544 5494 131 50140 50117 37815 1215 36097 5457 290 131 50118 50117 1594 36 40054 1215 37815 1215 36097 8061 2523 1215 36097 43 50118 50117 50117 37815 1215 36097 5457 10 3998 1215 37815 1215 36097 131 50118 50117 1594 36 417 40054 1215 37815 1215 36097 8061 2523 1215 36097 43 50118 50117 50117 37815 1215 36097 5457 385 40054 1215 37815 1215 36097 131 50140 50117 40054 1215 43776 10975 288 742 5457 128 37457 288 23500 50118 50117 1594 36 40054 43 25522 50118 50117 50117 40054 1215 43776 1215 43983 1215 6031 1640 40054 6 10 3998 1215 43776 4397 50118 50117 50117 4903 5457 10 3998 1215 6460 1215 12595 1640 40054 6 21147 1215 39679 4014 1215 5382 16802 6 359 40054 1215 1342 4397 50118 50117 50117 1594 36 4903 45994 321 43 50118 50117 50117 50117 40054 5457 48955 131 50118 50117 50117 1594 36 4903 28696 321 43 50118 50117 50117 50117 30921 5494 131 50118 50117 24303 50118 50117 417 40054 1215 43776 10975 288 742 5457 128 37457 288 23500 50118 50117 1594 36 417 40054 43 25522 50118 50117 50117 40054 1215 43776 1215 43983 1215 6031 1640 417 40054 6 385 40054 1215 43776 4397 50118 50117 50117 4903 5457 10 3998 1215 6460 1215 12595 1640 417 40054 6 21147 1215 39679 4014 1215 5382 16802 6 359 417 40054 1215 1342 4397 50118 50117 50117 1594 36 4903 45994 321 43 50118 50117 50117 50117 417 40054 5457 48955 131 50118 50117 50117 2
08/17/2022 17:06:58 - INFO - __main__ -   *** Example ***
08/17/2022 17:06:58 - INFO - __main__ -   label: 0
08/17/2022 17:06:58 - INFO - __main__ -   input_tokens: ['<s>', 'void', '_Fo', 'Fi', 'Type', '1', 'C', '::', 'read', 'FD', '(', 'int', '_offset', ',', '_int', '_length', ',', '_Type', '1', 'CP', 'riv', 'ate', 'D', 'ict', '_*', 'p', 'D', 'ict', ')', '_{', 'Ċ', '_', '_int', '_pos', ',', '_p', 'Size', ',', '_p', 'Offset', ';', 'Ċ', '_', '_double', '_font', 'Matrix', '[', '6', ']', '_=', '_{', '0', '};', 'Ċ', '_', '_GB', 'ool', '_has', 'Font', 'Matrix', ';', 'ĊĊ', '_', '_has', 'Font', 'Matrix', '_=', '_g', 'False', ';', 'Ċ', '_', '_font', 'Matrix', '[', '0', ']', '_=', '_font', 'Matrix', '[', '1', ']', '_=', '_font', 'Matrix', '[', '2', ']', '_=', '_0', ';', '_//', '_make', '_gcc', '_happy', 'Ċ', '_', '_font', 'Matrix', '[', '3', ']', '_=', '_font', 'Matrix', '[', '4', ']', '_=', '_font', 'Matrix', '[', '5', ']', '_=', '_0', ';', 'Ċ', '_', '_p', 'Size', '_=', '_p', 'Offset', '_=', '_0', ';', 'Ċ', '_', '_pos', '_=', '_offset', ';', 'Ċ', '_', '_n', 'Ops', '_=', '_0', ';', 'Ċ', '_', '_while', '_(', 'pos', '_<', '_offset', '_+', '_length', ')', '_{', 'Ċ', '_', '_', '_', '_pos', '_=', '_get', 'Op', '(', 'pos', ',', '_g', 'False', ',', '_&', 'p', 'ars', 'ed', 'Ok', ');', 'Ċ', '_', '_', '_', '_if', '_(!', 'p', 'ars', 'ed', 'Ok', ')', '_{', 'Ċ', '_', '_', '_', '_', '_', '_return', ';', 'Ċ', '_', '_', '_', '_}', 'Ċ', '_', '_', '_', '_if', '_(!', 'ops', '[', 'n', 'Ops', '_-', '_1', '].', 'is', 'Num', ')', '_{', 'Ċ', '_', '_', '_', '_', '_', '_if', '_(', 'ops', '[', 'n', 'Ops', '_-', '_1', '].', 'op', '_==', '_0', 'x', '00', '12', ')', '_{', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_if', '_(', 'n', 'Ops', '_<', '_3', ')', '_{', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_parsed', 'Ok', '_=', '_g', 'False', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_return', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_}', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_p', 'Size', '_=', '_(', 'int', ')', 'ops', '[', '0', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_p', 'Offset', '_=', '_(', 'int', ')', 'ops', '[', '1', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_break', ';', 'Ċ', '_', '_', '_', '_', '_', '_}', '_else', '_if', '_(', 'ops', '[', 'n', 'Ops', '_-', '_1', '].', 'op', '_==', '_0', 'x', '0', 'c', '07', ')', '_{', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_font', 'Matrix', '[', '0', ']', '_=', '_ops', '[', '0', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_font', 'Matrix', '[', '1', ']', '_=', '_ops', '[', '1', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_font', 'Matrix', '[', '2', ']', '_=', '_ops', '[', '2', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_font', 'Matrix', '[', '3', ']', '_=', '_ops', '[', '3', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_font', 'Matrix', '[', '4', ']', '_=', '_ops', '[', '4', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_font', 'Matrix', '[', '5', ']', '_=', '_ops', '[', '5', '].', 'num', ';', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_has', 'Font', 'Matrix', '_=', '_g', 'True', ';', 'Ċ', '_', '_', '_', '_', '_', '_}', 'Ċ', '_', '_', '</s>']
08/17/2022 17:06:58 - INFO - __main__ -   input_ids: 0 47908 18357 9474 40118 134 347 38304 12745 24667 1640 2544 6147 6 6979 5933 6 7773 134 7496 16936 877 495 11726 1009 642 495 11726 43 25522 50118 1437 6979 8593 6 181 45698 6 181 48772 131 50118 1437 1457 28716 47360 10975 401 742 5457 25522 288 49423 50118 1437 7216 8110 34 46197 47360 131 50140 1437 34 46197 47360 5457 821 46659 131 50118 1437 28716 47360 10975 288 742 5457 28716 47360 10975 134 742 5457 28716 47360 10975 176 742 5457 321 131 21277 146 49353 1372 50118 1437 28716 47360 10975 246 742 5457 28716 47360 10975 306 742 5457 28716 47360 10975 245 742 5457 321 131 50118 1437 181 45698 5457 181 48772 5457 321 131 50118 1437 8593 5457 6147 131 50118 1437 295 36421 5457 321 131 50118 1437 150 36 11474 28696 6147 2055 5933 43 25522 50118 1437 1437 1437 8593 5457 120 13926 1640 11474 6 821 46659 6 359 642 2726 196 26752 4397 50118 1437 1437 1437 114 48209 642 2726 196 26752 43 25522 50118 1437 1437 1437 1437 1437 671 131 50118 1437 1437 1437 35524 50118 1437 1437 1437 114 48209 5090 10975 282 36421 111 112 8174 354 48184 43 25522 50118 1437 1437 1437 1437 1437 114 36 5090 10975 282 36421 111 112 8174 1517 45994 321 1178 612 1092 43 25522 50118 1437 1437 1437 1437 1437 1437 1437 114 36 282 36421 28696 155 43 25522 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 47367 26752 5457 821 46659 131 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 671 131 50118 1437 1437 1437 1437 1437 1437 1437 35524 50118 1437 1437 1437 1437 1437 1437 1437 181 45698 5457 36 2544 43 5090 10975 288 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 181 48772 5457 36 2544 43 5090 10975 134 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 1108 131 50118 1437 1437 1437 1437 1437 35524 1493 114 36 5090 10975 282 36421 111 112 8174 1517 45994 321 1178 288 438 3570 43 25522 50118 1437 1437 1437 1437 1437 1437 1437 28716 47360 10975 288 742 5457 38801 10975 288 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 28716 47360 10975 134 742 5457 38801 10975 134 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 28716 47360 10975 176 742 5457 38801 10975 176 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 28716 47360 10975 246 742 5457 38801 10975 246 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 28716 47360 10975 306 742 5457 38801 10975 306 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 28716 47360 10975 245 742 5457 38801 10975 245 8174 42666 131 50118 1437 1437 1437 1437 1437 1437 1437 34 46197 47360 5457 821 36948 131 50118 1437 1437 1437 1437 1437 35524 50118 1437 1437 2
08/17/2022 17:06:58 - INFO - __main__ -   *** Example ***
08/17/2022 17:06:58 - INFO - __main__ -   label: 0
08/17/2022 17:06:58 - INFO - __main__ -   input_tokens: ['<s>', 're', '_', 'input', '_(', 'void', ')', 'Ċ', '{', 'Ċ', '_', '_', '_', '_if', '_(', 'using', '_', 'plan', '_', 'a', ')', '_{', 'Ċ', '_', '_', '_', '_', '_', '_if', '_(', 'i', '_', 'buffer', ')', 'Ċ', 'ĉ', '{', 'Ċ', 'ĉ', '_', '_free', '_(', 'i', '_', 'buffer', ');', 'Ċ', 'ĉ', '_', '_i', '_', 'buffer', '_=', '_0', ';', 'Ċ', 'ĉ', '_', '_free', '_(', 'i', '_', 'ptr', ');', 'Ċ', 'ĉ', '}', 'Ċ', '_', '_', '_', '_}', 'Ċ', '_', '_', '_', '_else', '_{', 'Ċ', 'ĉ', 'if', '_(', 'tif', 'd', '_>=', '_0', ')', 'Ċ', 'ĉ', '_', '_close', '_(', 'tif', 'd', ');', 'Ċ', 'ĉ', 'tif', 'd', '_=', '_-', '1', ';', 'Ċ', 'ĉ', 'if', '_(', 't', 'ib', 'uf', '[', '0', '])', 'Ċ', 'ĉ', '_', '_{', 'Ċ', 'ĉ', '_', '_', '_', '_free', '_(', 't', 'ib', 'uf', '[', '0', ']);', 'Ċ', 'ĉ', '_', '_', '_', '_t', 'ib', 'uf', '[', '0', ']', '_=', '_0', ';', 'Ċ', 'ĉ', '_', '_}', 'Ċ', 'ĉ', 'til', 'ine', '[', '0', ']', '_=', '_til', 'ine', '[', '1', ']', '_=', '_-', '1', ';', 'Ċ', 'ĉ', 't', 'ire', 'cl', 'en', '_=', '_0', ';', 'Ċ', '_', '_', '_', '_}', 'Ċ', '}', 'Ċ', '</s>']
08/17/2022 17:06:58 - INFO - __main__ -   input_ids: 0 241 1215 46797 36 47908 43 50118 45152 50118 1437 1437 1437 114 36 10928 1215 11181 1215 102 43 25522 50118 1437 1437 1437 1437 1437 114 36 118 1215 47438 43 50118 50117 45152 50118 50117 1437 481 36 118 1215 47438 4397 50118 50117 1437 939 1215 47438 5457 321 131 50118 50117 1437 481 36 118 1215 43880 4397 50118 50117 24303 50118 1437 1437 1437 35524 50118 1437 1437 1437 1493 25522 50118 50117 1594 36 48609 417 49095 321 43 50118 50117 1437 593 36 48609 417 4397 50118 50117 48609 417 5457 111 134 131 50118 50117 1594 36 90 1452 2951 10975 288 45587 50118 50117 1437 25522 50118 50117 1437 1437 1437 481 36 90 1452 2951 10975 288 48601 50118 50117 1437 1437 1437 326 1452 2951 10975 288 742 5457 321 131 50118 50117 1437 35524 50118 50117 31387 833 10975 288 742 5457 19976 833 10975 134 742 5457 111 134 131 50118 50117 90 1885 3998 225 5457 321 131 50118 1437 1437 1437 35524 50118 24303 50118 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
load dataset:   0%|          | 0/27 [00:00<?, ?it/s]load dataset: 100%|██████████| 27/27 [00:00<00:00, 408.59it/s]
/home/<ANONYMOUS>/code/LineVul/venv/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
08/17/2022 17:07:00 - INFO - __main__ -   ***** Running training *****
08/17/2022 17:07:00 - INFO - __main__ -     Num examples = 429
08/17/2022 17:07:00 - INFO - __main__ -     Num Epochs = 10
08/17/2022 17:07:00 - INFO - __main__ -     Instantaneous batch size per GPU = 16
08/17/2022 17:07:00 - INFO - __main__ -     Total train batch size = 16
08/17/2022 17:07:00 - INFO - __main__ -     Gradient Accumulation steps = 1
08/17/2022 17:07:00 - INFO - __main__ -     Total optimization steps = 270
  0%|          | 0/27 [00:00<?, ?it/s]epoch 0 loss 0.69548:   0%|          | 0/27 [00:01<?, ?it/s]epoch 0 loss 0.69548:   4%|▎         | 1/27 [00:01<00:32,  1.24s/it]epoch 0 loss 0.70735:   4%|▎         | 1/27 [00:01<00:32,  1.24s/it]epoch 0 loss 0.70735:   7%|▋         | 2/27 [00:01<00:19,  1.31it/s]epoch 0 loss 0.72125:   7%|▋         | 2/27 [00:02<00:19,  1.31it/s]epoch 0 loss 0.72125:  11%|█         | 3/27 [00:02<00:15,  1.60it/s]epoch 0 loss 0.71422:  11%|█         | 3/27 [00:02<00:15,  1.60it/s]epoch 0 loss 0.71422:  15%|█▍        | 4/27 [00:02<00:12,  1.86it/s]epoch 0 loss 0.71395:  15%|█▍        | 4/27 [00:02<00:12,  1.86it/s]epoch 0 loss 0.71395:  19%|█▊        | 5/27 [00:02<00:10,  2.01it/s]epoch 0 loss 0.71557:  19%|█▊        | 5/27 [00:03<00:10,  2.01it/s]epoch 0 loss 0.71557:  22%|██▏       | 6/27 [00:03<00:10,  2.05it/s]epoch 0 loss 0.71545:  22%|██▏       | 6/27 [00:03<00:10,  2.05it/s]epoch 0 loss 0.71545:  26%|██▌       | 7/27 [00:03<00:09,  2.21it/s]epoch 0 loss 0.70992:  26%|██▌       | 7/27 [00:04<00:09,  2.21it/s]epoch 0 loss 0.70992:  30%|██▉       | 8/27 [00:04<00:08,  2.28it/s]epoch 0 loss 0.70467:  30%|██▉       | 8/27 [00:04<00:08,  2.28it/s]epoch 0 loss 0.70467:  33%|███▎      | 9/27 [00:04<00:07,  2.25it/s]epoch 0 loss 0.70284:  33%|███▎      | 9/27 [00:05<00:07,  2.25it/s]epoch 0 loss 0.70284:  37%|███▋      | 10/27 [00:05<00:07,  2.32it/s]epoch 0 loss 0.70153:  37%|███▋      | 10/27 [00:05<00:07,  2.32it/s]epoch 0 loss 0.70153:  41%|████      | 11/27 [00:05<00:06,  2.37it/s]epoch 0 loss 0.70132:  41%|████      | 11/27 [00:05<00:06,  2.37it/s]epoch 0 loss 0.70132:  44%|████▍     | 12/27 [00:05<00:06,  2.32it/s]epoch 0 loss 0.70135:  44%|████▍     | 12/27 [00:06<00:06,  2.32it/s]epoch 0 loss 0.70135:  48%|████▊     | 13/27 [00:06<00:05,  2.39it/s]epoch 0 loss 0.69798:  48%|████▊     | 13/27 [00:06<00:05,  2.39it/s]epoch 0 loss 0.69798:  52%|█████▏    | 14/27 [00:06<00:05,  2.41it/s]epoch 0 loss 0.69553:  52%|█████▏    | 14/27 [00:07<00:05,  2.41it/s]epoch 0 loss 0.69553:  56%|█████▌    | 15/27 [00:07<00:05,  2.32it/s]epoch 0 loss 0.69692:  56%|█████▌    | 15/27 [00:07<00:05,  2.32it/s]epoch 0 loss 0.69692:  59%|█████▉    | 16/27 [00:07<00:04,  2.36it/s]epoch 0 loss 0.69482:  59%|█████▉    | 16/27 [00:07<00:04,  2.36it/s]epoch 0 loss 0.69482:  63%|██████▎   | 17/27 [00:08<00:04,  2.38it/s]epoch 0 loss 0.697:  63%|██████▎   | 17/27 [00:08<00:04,  2.38it/s]  epoch 0 loss 0.697:  67%|██████▋   | 18/27 [00:08<00:03,  2.29it/s]epoch 0 loss 0.6973:  67%|██████▋   | 18/27 [00:08<00:03,  2.29it/s]epoch 0 loss 0.6973:  70%|███████   | 19/27 [00:08<00:03,  2.33it/s]epoch 0 loss 0.69829:  70%|███████   | 19/27 [00:09<00:03,  2.33it/s]epoch 0 loss 0.69829:  74%|███████▍  | 20/27 [00:09<00:02,  2.34it/s]epoch 0 loss 0.69699:  74%|███████▍  | 20/27 [00:09<00:02,  2.34it/s]epoch 0 loss 0.69699:  78%|███████▊  | 21/27 [00:09<00:02,  2.26it/s]epoch 0 loss 0.6947:  78%|███████▊  | 21/27 [00:10<00:02,  2.26it/s] epoch 0 loss 0.6947:  81%|████████▏ | 22/27 [00:10<00:02,  2.33it/s]epoch 0 loss 0.69493:  81%|████████▏ | 22/27 [00:10<00:02,  2.33it/s]epoch 0 loss 0.69493:  85%|████████▌ | 23/27 [00:10<00:01,  2.38it/s]epoch 0 loss 0.69544:  85%|████████▌ | 23/27 [00:11<00:01,  2.38it/s]epoch 0 loss 0.69544:  89%|████████▉ | 24/27 [00:11<00:01,  2.31it/s]epoch 0 loss 0.69572:  89%|████████▉ | 24/27 [00:11<00:01,  2.31it/s]epoch 0 loss 0.69572:  93%|█████████▎| 25/27 [00:11<00:00,  2.35it/s]epoch 0 loss 0.69706:  93%|█████████▎| 25/27 [00:11<00:00,  2.35it/s]epoch 0 loss 0.69706:  96%|█████████▋| 26/27 [00:11<00:00,  2.37it/s]epoch 0 loss 0.69784:  96%|█████████▋| 26/27 [00:12<00:00,  2.37it/s]08/17/2022 17:07:12 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:07:12 - INFO - __main__ -     Num examples = 27
08/17/2022 17:07:12 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.48it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.63it/s]
/home/<ANONYMOUS>/code/LineVul/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
08/17/2022 17:07:12 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:07:12 - INFO - __main__ -     eval_f1 = 0.0
08/17/2022 17:07:12 - INFO - __main__ -     eval_precision = 0.0
08/17/2022 17:07:12 - INFO - __main__ -     eval_recall = 0.0
08/17/2022 17:07:12 - INFO - __main__ -     eval_threshold = 0.5
epoch 0 loss 0.69784: 100%|██████████| 27/27 [00:12<00:00,  2.09it/s]epoch 0 loss 0.69784: 100%|██████████| 27/27 [00:12<00:00,  2.16it/s]
08/17/2022 17:07:14 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 1 loss 0.65121:   0%|          | 0/27 [00:00<?, ?it/s]epoch 1 loss 0.65121:   4%|▎         | 1/27 [00:00<00:10,  2.42it/s]epoch 1 loss 0.66379:   4%|▎         | 1/27 [00:00<00:10,  2.42it/s]epoch 1 loss 0.66379:   7%|▋         | 2/27 [00:00<00:10,  2.35it/s]epoch 1 loss 0.68069:   7%|▋         | 2/27 [00:01<00:10,  2.35it/s]epoch 1 loss 0.68069:  11%|█         | 3/27 [00:01<00:10,  2.26it/s]epoch 1 loss 0.6955:  11%|█         | 3/27 [00:01<00:10,  2.26it/s] epoch 1 loss 0.6955:  15%|█▍        | 4/27 [00:01<00:09,  2.36it/s]epoch 1 loss 0.69392:  15%|█▍        | 4/27 [00:02<00:09,  2.36it/s]epoch 1 loss 0.69392:  19%|█▊        | 5/27 [00:02<00:09,  2.39it/s]epoch 1 loss 0.69216:  19%|█▊        | 5/27 [00:02<00:09,  2.39it/s]epoch 1 loss 0.69216:  22%|██▏       | 6/27 [00:02<00:09,  2.32it/s]epoch 1 loss 0.69354:  22%|██▏       | 6/27 [00:02<00:09,  2.32it/s]epoch 1 loss 0.69354:  26%|██▌       | 7/27 [00:02<00:08,  2.39it/s]epoch 1 loss 0.69298:  26%|██▌       | 7/27 [00:03<00:08,  2.39it/s]epoch 1 loss 0.69298:  30%|██▉       | 8/27 [00:03<00:07,  2.38it/s]epoch 1 loss 0.69348:  30%|██▉       | 8/27 [00:03<00:07,  2.38it/s]epoch 1 loss 0.69348:  33%|███▎      | 9/27 [00:03<00:07,  2.33it/s]epoch 1 loss 0.6946:  33%|███▎      | 9/27 [00:04<00:07,  2.33it/s] epoch 1 loss 0.6946:  37%|███▋      | 10/27 [00:04<00:07,  2.39it/s]epoch 1 loss 0.69468:  37%|███▋      | 10/27 [00:04<00:07,  2.39it/s]epoch 1 loss 0.69468:  41%|████      | 11/27 [00:04<00:06,  2.36it/s]epoch 1 loss 0.69383:  41%|████      | 11/27 [00:05<00:06,  2.36it/s]epoch 1 loss 0.69383:  44%|████▍     | 12/27 [00:05<00:06,  2.33it/s]epoch 1 loss 0.69625:  44%|████▍     | 12/27 [00:05<00:06,  2.33it/s]epoch 1 loss 0.69625:  48%|████▊     | 13/27 [00:05<00:05,  2.39it/s]epoch 1 loss 0.69739:  48%|████▊     | 13/27 [00:05<00:05,  2.39it/s]epoch 1 loss 0.69739:  52%|█████▏    | 14/27 [00:05<00:05,  2.41it/s]epoch 1 loss 0.69864:  52%|█████▏    | 14/27 [00:06<00:05,  2.41it/s]epoch 1 loss 0.69864:  56%|█████▌    | 15/27 [00:06<00:05,  2.32it/s]epoch 1 loss 0.70118:  56%|█████▌    | 15/27 [00:06<00:05,  2.32it/s]epoch 1 loss 0.70118:  59%|█████▉    | 16/27 [00:06<00:04,  2.40it/s]epoch 1 loss 0.70084:  59%|█████▉    | 16/27 [00:07<00:04,  2.40it/s]epoch 1 loss 0.70084:  63%|██████▎   | 17/27 [00:07<00:04,  2.43it/s]epoch 1 loss 0.69929:  63%|██████▎   | 17/27 [00:07<00:04,  2.43it/s]epoch 1 loss 0.69929:  67%|██████▋   | 18/27 [00:07<00:03,  2.35it/s]epoch 1 loss 0.69973:  67%|██████▋   | 18/27 [00:07<00:03,  2.35it/s]epoch 1 loss 0.69973:  70%|███████   | 19/27 [00:08<00:03,  2.39it/s]epoch 1 loss 0.70204:  70%|███████   | 19/27 [00:08<00:03,  2.39it/s]epoch 1 loss 0.70204:  74%|███████▍  | 20/27 [00:08<00:02,  2.40it/s]epoch 1 loss 0.70084:  74%|███████▍  | 20/27 [00:08<00:02,  2.40it/s]epoch 1 loss 0.70084:  78%|███████▊  | 21/27 [00:08<00:02,  2.32it/s]epoch 1 loss 0.6998:  78%|███████▊  | 21/27 [00:09<00:02,  2.32it/s] epoch 1 loss 0.6998:  81%|████████▏ | 22/27 [00:09<00:02,  2.37it/s]epoch 1 loss 0.70008:  81%|████████▏ | 22/27 [00:09<00:02,  2.37it/s]epoch 1 loss 0.70008:  85%|████████▌ | 23/27 [00:09<00:01,  2.38it/s]epoch 1 loss 0.69912:  85%|████████▌ | 23/27 [00:10<00:01,  2.38it/s]epoch 1 loss 0.69912:  89%|████████▉ | 24/27 [00:10<00:01,  2.30it/s]epoch 1 loss 0.70117:  89%|████████▉ | 24/27 [00:10<00:01,  2.30it/s]epoch 1 loss 0.70117:  93%|█████████▎| 25/27 [00:10<00:00,  2.35it/s]epoch 1 loss 0.7009:  93%|█████████▎| 25/27 [00:10<00:00,  2.35it/s] epoch 1 loss 0.7009:  96%|█████████▋| 26/27 [00:10<00:00,  2.37it/s]epoch 1 loss 0.69986:  96%|█████████▋| 26/27 [00:11<00:00,  2.37it/s]08/17/2022 17:07:26 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:07:26 - INFO - __main__ -     Num examples = 27
08/17/2022 17:07:26 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.08it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.36it/s]
08/17/2022 17:07:26 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:07:26 - INFO - __main__ -     eval_f1 = 0.5333
08/17/2022 17:07:26 - INFO - __main__ -     eval_precision = 0.7273
08/17/2022 17:07:26 - INFO - __main__ -     eval_recall = 0.4211
08/17/2022 17:07:26 - INFO - __main__ -     eval_threshold = 0.5
08/17/2022 17:07:26 - INFO - __main__ -     ********************
08/17/2022 17:07:26 - INFO - __main__ -     Best f1:0.5333
08/17/2022 17:07:26 - INFO - __main__ -     ********************
08/17/2022 17:07:28 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-best-f1/model.bin
epoch 1 loss 0.69986: 100%|██████████| 27/27 [00:13<00:00,  1.03s/it]epoch 1 loss 0.69986: 100%|██████████| 27/27 [00:13<00:00,  2.01it/s]
08/17/2022 17:07:31 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 2 loss 0.64029:   0%|          | 0/27 [00:00<?, ?it/s]epoch 2 loss 0.64029:   4%|▎         | 1/27 [00:00<00:10,  2.38it/s]epoch 2 loss 0.64091:   4%|▎         | 1/27 [00:00<00:10,  2.38it/s]epoch 2 loss 0.64091:   7%|▋         | 2/27 [00:00<00:11,  2.24it/s]epoch 2 loss 0.64053:   7%|▋         | 2/27 [00:01<00:11,  2.24it/s]epoch 2 loss 0.64053:  11%|█         | 3/27 [00:01<00:10,  2.39it/s]epoch 2 loss 0.63663:  11%|█         | 3/27 [00:01<00:10,  2.39it/s]epoch 2 loss 0.63663:  15%|█▍        | 4/27 [00:01<00:09,  2.37it/s]epoch 2 loss 0.6447:  15%|█▍        | 4/27 [00:02<00:09,  2.37it/s] epoch 2 loss 0.6447:  19%|█▊        | 5/27 [00:02<00:09,  2.28it/s]epoch 2 loss 0.664:  19%|█▊        | 5/27 [00:02<00:09,  2.28it/s] epoch 2 loss 0.664:  22%|██▏       | 6/27 [00:02<00:08,  2.37it/s]epoch 2 loss 0.67551:  22%|██▏       | 6/27 [00:02<00:08,  2.37it/s]epoch 2 loss 0.67551:  26%|██▌       | 7/27 [00:02<00:08,  2.41it/s]epoch 2 loss 0.67802:  26%|██▌       | 7/27 [00:03<00:08,  2.41it/s]epoch 2 loss 0.67802:  30%|██▉       | 8/27 [00:03<00:08,  2.32it/s]epoch 2 loss 0.67661:  30%|██▉       | 8/27 [00:03<00:08,  2.32it/s]epoch 2 loss 0.67661:  33%|███▎      | 9/27 [00:03<00:07,  2.40it/s]epoch 2 loss 0.68546:  33%|███▎      | 9/27 [00:04<00:07,  2.40it/s]epoch 2 loss 0.68546:  37%|███▋      | 10/27 [00:04<00:06,  2.44it/s]epoch 2 loss 0.67871:  37%|███▋      | 10/27 [00:04<00:06,  2.44it/s]epoch 2 loss 0.67871:  41%|████      | 11/27 [00:04<00:06,  2.32it/s]epoch 2 loss 0.68304:  41%|████      | 11/27 [00:05<00:06,  2.32it/s]epoch 2 loss 0.68304:  44%|████▍     | 12/27 [00:05<00:06,  2.41it/s]epoch 2 loss 0.676:  44%|████▍     | 12/27 [00:05<00:06,  2.41it/s]  epoch 2 loss 0.676:  48%|████▊     | 13/27 [00:05<00:05,  2.44it/s]epoch 2 loss 0.67465:  48%|████▊     | 13/27 [00:05<00:05,  2.44it/s]epoch 2 loss 0.67465:  52%|█████▏    | 14/27 [00:05<00:05,  2.36it/s]epoch 2 loss 0.6744:  52%|█████▏    | 14/27 [00:06<00:05,  2.36it/s] epoch 2 loss 0.6744:  56%|█████▌    | 15/27 [00:06<00:04,  2.43it/s]epoch 2 loss 0.67213:  56%|█████▌    | 15/27 [00:06<00:04,  2.43it/s]epoch 2 loss 0.67213:  59%|█████▉    | 16/27 [00:06<00:04,  2.45it/s]epoch 2 loss 0.6754:  59%|█████▉    | 16/27 [00:07<00:04,  2.45it/s] epoch 2 loss 0.6754:  63%|██████▎   | 17/27 [00:07<00:04,  2.36it/s]epoch 2 loss 0.67597:  63%|██████▎   | 17/27 [00:07<00:04,  2.36it/s]epoch 2 loss 0.67597:  67%|██████▋   | 18/27 [00:07<00:03,  2.42it/s]epoch 2 loss 0.67546:  67%|██████▋   | 18/27 [00:07<00:03,  2.42it/s]epoch 2 loss 0.67546:  70%|███████   | 19/27 [00:07<00:03,  2.44it/s]epoch 2 loss 0.67985:  70%|███████   | 19/27 [00:08<00:03,  2.44it/s]epoch 2 loss 0.67985:  74%|███████▍  | 20/27 [00:08<00:02,  2.40it/s]epoch 2 loss 0.67719:  74%|███████▍  | 20/27 [00:08<00:02,  2.40it/s]epoch 2 loss 0.67719:  78%|███████▊  | 21/27 [00:08<00:02,  2.43it/s]epoch 2 loss 0.67336:  78%|███████▊  | 21/27 [00:09<00:02,  2.43it/s]epoch 2 loss 0.67336:  81%|████████▏ | 22/27 [00:09<00:02,  2.43it/s]epoch 2 loss 0.67216:  81%|████████▏ | 22/27 [00:09<00:02,  2.43it/s]epoch 2 loss 0.67216:  85%|████████▌ | 23/27 [00:09<00:01,  2.41it/s]epoch 2 loss 0.67258:  85%|████████▌ | 23/27 [00:09<00:01,  2.41it/s]epoch 2 loss 0.67258:  89%|████████▉ | 24/27 [00:10<00:01,  2.43it/s]epoch 2 loss 0.67085:  89%|████████▉ | 24/27 [00:10<00:01,  2.43it/s]epoch 2 loss 0.67085:  93%|█████████▎| 25/27 [00:10<00:00,  2.44it/s]epoch 2 loss 0.67156:  93%|█████████▎| 25/27 [00:10<00:00,  2.44it/s]epoch 2 loss 0.67156:  96%|█████████▋| 26/27 [00:10<00:00,  2.42it/s]epoch 2 loss 0.67055:  96%|█████████▋| 26/27 [00:11<00:00,  2.42it/s]08/17/2022 17:07:42 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:07:42 - INFO - __main__ -     Num examples = 27
08/17/2022 17:07:42 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.26it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.57it/s]
08/17/2022 17:07:43 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:07:43 - INFO - __main__ -     eval_f1 = 0.7179
08/17/2022 17:07:43 - INFO - __main__ -     eval_precision = 0.7
08/17/2022 17:07:43 - INFO - __main__ -     eval_recall = 0.7368
08/17/2022 17:07:43 - INFO - __main__ -     eval_threshold = 0.5
08/17/2022 17:07:43 - INFO - __main__ -     ********************
08/17/2022 17:07:43 - INFO - __main__ -     Best f1:0.7179
08/17/2022 17:07:43 - INFO - __main__ -     ********************
08/17/2022 17:07:45 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-best-f1/model.bin
epoch 2 loss 0.67055: 100%|██████████| 27/27 [00:13<00:00,  1.14s/it]epoch 2 loss 0.67055: 100%|██████████| 27/27 [00:13<00:00,  1.97it/s]
08/17/2022 17:07:48 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 3 loss 0.64493:   0%|          | 0/27 [00:00<?, ?it/s]epoch 3 loss 0.64493:   4%|▎         | 1/27 [00:00<00:10,  2.54it/s]epoch 3 loss 0.65497:   4%|▎         | 1/27 [00:00<00:10,  2.54it/s]epoch 3 loss 0.65497:   7%|▋         | 2/27 [00:00<00:10,  2.45it/s]epoch 3 loss 0.6355:   7%|▋         | 2/27 [00:01<00:10,  2.45it/s] epoch 3 loss 0.6355:  11%|█         | 3/27 [00:01<00:09,  2.46it/s]epoch 3 loss 0.63664:  11%|█         | 3/27 [00:01<00:09,  2.46it/s]epoch 3 loss 0.63664:  15%|█▍        | 4/27 [00:01<00:09,  2.44it/s]epoch 3 loss 0.63311:  15%|█▍        | 4/27 [00:02<00:09,  2.44it/s]epoch 3 loss 0.63311:  19%|█▊        | 5/27 [00:02<00:09,  2.34it/s]epoch 3 loss 0.6323:  19%|█▊        | 5/27 [00:02<00:09,  2.34it/s] epoch 3 loss 0.6323:  22%|██▏       | 6/27 [00:02<00:08,  2.39it/s]epoch 3 loss 0.65387:  22%|██▏       | 6/27 [00:02<00:08,  2.39it/s]epoch 3 loss 0.65387:  26%|██▌       | 7/27 [00:02<00:08,  2.46it/s]epoch 3 loss 0.63766:  26%|██▌       | 7/27 [00:03<00:08,  2.46it/s]epoch 3 loss 0.63766:  30%|██▉       | 8/27 [00:03<00:07,  2.44it/s]epoch 3 loss 0.64495:  30%|██▉       | 8/27 [00:03<00:07,  2.44it/s]epoch 3 loss 0.64495:  33%|███▎      | 9/27 [00:03<00:07,  2.38it/s]epoch 3 loss 0.64349:  33%|███▎      | 9/27 [00:04<00:07,  2.38it/s]epoch 3 loss 0.64349:  37%|███▋      | 10/27 [00:04<00:07,  2.43it/s]epoch 3 loss 0.64103:  37%|███▋      | 10/27 [00:04<00:07,  2.43it/s]epoch 3 loss 0.64103:  41%|████      | 11/27 [00:04<00:06,  2.41it/s]epoch 3 loss 0.64268:  41%|████      | 11/27 [00:04<00:06,  2.41it/s]epoch 3 loss 0.64268:  44%|████▍     | 12/27 [00:05<00:06,  2.33it/s]epoch 3 loss 0.63839:  44%|████▍     | 12/27 [00:05<00:06,  2.33it/s]epoch 3 loss 0.63839:  48%|████▊     | 13/27 [00:05<00:05,  2.41it/s]epoch 3 loss 0.63655:  48%|████▊     | 13/27 [00:05<00:05,  2.41it/s]epoch 3 loss 0.63655:  52%|█████▏    | 14/27 [00:05<00:05,  2.40it/s]epoch 3 loss 0.64072:  52%|█████▏    | 14/27 [00:06<00:05,  2.40it/s]epoch 3 loss 0.64072:  56%|█████▌    | 15/27 [00:06<00:05,  2.36it/s]epoch 3 loss 0.64371:  56%|█████▌    | 15/27 [00:06<00:05,  2.36it/s]epoch 3 loss 0.64371:  59%|█████▉    | 16/27 [00:06<00:04,  2.41it/s]epoch 3 loss 0.63986:  59%|█████▉    | 16/27 [00:07<00:04,  2.41it/s]epoch 3 loss 0.63986:  63%|██████▎   | 17/27 [00:07<00:04,  2.38it/s]epoch 3 loss 0.63767:  63%|██████▎   | 17/27 [00:07<00:04,  2.38it/s]epoch 3 loss 0.63767:  67%|██████▋   | 18/27 [00:07<00:03,  2.31it/s]epoch 3 loss 0.63081:  67%|██████▋   | 18/27 [00:07<00:03,  2.31it/s]epoch 3 loss 0.63081:  70%|███████   | 19/27 [00:07<00:03,  2.40it/s]epoch 3 loss 0.63218:  70%|███████   | 19/27 [00:08<00:03,  2.40it/s]epoch 3 loss 0.63218:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 3 loss 0.62685:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 3 loss 0.62685:  78%|███████▊  | 21/27 [00:08<00:02,  2.36it/s]epoch 3 loss 0.62455:  78%|███████▊  | 21/27 [00:09<00:02,  2.36it/s]epoch 3 loss 0.62455:  81%|████████▏ | 22/27 [00:09<00:02,  2.41it/s]epoch 3 loss 0.62635:  81%|████████▏ | 22/27 [00:09<00:02,  2.41it/s]epoch 3 loss 0.62635:  85%|████████▌ | 23/27 [00:09<00:01,  2.41it/s]epoch 3 loss 0.62691:  85%|████████▌ | 23/27 [00:10<00:01,  2.41it/s]epoch 3 loss 0.62691:  89%|████████▉ | 24/27 [00:10<00:01,  2.37it/s]epoch 3 loss 0.62831:  89%|████████▉ | 24/27 [00:10<00:01,  2.37it/s]epoch 3 loss 0.62831:  93%|█████████▎| 25/27 [00:10<00:00,  2.43it/s]epoch 3 loss 0.62694:  93%|█████████▎| 25/27 [00:10<00:00,  2.43it/s]epoch 3 loss 0.62694:  96%|█████████▋| 26/27 [00:10<00:00,  2.40it/s]epoch 3 loss 0.62374:  96%|█████████▋| 26/27 [00:11<00:00,  2.40it/s]08/17/2022 17:07:59 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:07:59 - INFO - __main__ -     Num examples = 27
08/17/2022 17:07:59 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.57it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.84it/s]
08/17/2022 17:07:59 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:07:59 - INFO - __main__ -     eval_f1 = 0.4
08/17/2022 17:07:59 - INFO - __main__ -     eval_precision = 0.8333
08/17/2022 17:07:59 - INFO - __main__ -     eval_recall = 0.2632
08/17/2022 17:07:59 - INFO - __main__ -     eval_threshold = 0.5
epoch 3 loss 0.62374: 100%|██████████| 27/27 [00:11<00:00,  2.13it/s]epoch 3 loss 0.62374: 100%|██████████| 27/27 [00:11<00:00,  2.36it/s]
08/17/2022 17:08:02 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 4 loss 0.62038:   0%|          | 0/27 [00:00<?, ?it/s]epoch 4 loss 0.62038:   4%|▎         | 1/27 [00:00<00:09,  2.61it/s]epoch 4 loss 0.63674:   4%|▎         | 1/27 [00:00<00:09,  2.61it/s]epoch 4 loss 0.63674:   7%|▋         | 2/27 [00:00<00:10,  2.33it/s]epoch 4 loss 0.60701:   7%|▋         | 2/27 [00:01<00:10,  2.33it/s]epoch 4 loss 0.60701:  11%|█         | 3/27 [00:01<00:09,  2.43it/s]epoch 4 loss 0.56547:  11%|█         | 3/27 [00:01<00:09,  2.43it/s]epoch 4 loss 0.56547:  15%|█▍        | 4/27 [00:01<00:09,  2.42it/s]epoch 4 loss 0.57053:  15%|█▍        | 4/27 [00:02<00:09,  2.42it/s]epoch 4 loss 0.57053:  19%|█▊        | 5/27 [00:02<00:09,  2.30it/s]epoch 4 loss 0.59842:  19%|█▊        | 5/27 [00:02<00:09,  2.30it/s]epoch 4 loss 0.59842:  22%|██▏       | 6/27 [00:02<00:08,  2.36it/s]epoch 4 loss 0.60257:  22%|██▏       | 6/27 [00:02<00:08,  2.36it/s]epoch 4 loss 0.60257:  26%|██▌       | 7/27 [00:02<00:08,  2.37it/s]epoch 4 loss 0.61411:  26%|██▌       | 7/27 [00:03<00:08,  2.37it/s]epoch 4 loss 0.61411:  30%|██▉       | 8/27 [00:03<00:08,  2.30it/s]epoch 4 loss 0.59801:  30%|██▉       | 8/27 [00:03<00:08,  2.30it/s]epoch 4 loss 0.59801:  33%|███▎      | 9/27 [00:03<00:07,  2.37it/s]epoch 4 loss 0.58396:  33%|███▎      | 9/27 [00:04<00:07,  2.37it/s]epoch 4 loss 0.58396:  37%|███▋      | 10/27 [00:04<00:07,  2.39it/s]epoch 4 loss 0.58281:  37%|███▋      | 10/27 [00:04<00:07,  2.39it/s]epoch 4 loss 0.58281:  41%|████      | 11/27 [00:04<00:06,  2.32it/s]epoch 4 loss 0.58298:  41%|████      | 11/27 [00:05<00:06,  2.32it/s]epoch 4 loss 0.58298:  44%|████▍     | 12/27 [00:05<00:06,  2.39it/s]epoch 4 loss 0.58279:  44%|████▍     | 12/27 [00:05<00:06,  2.39it/s]epoch 4 loss 0.58279:  48%|████▊     | 13/27 [00:05<00:05,  2.39it/s]epoch 4 loss 0.57196:  48%|████▊     | 13/27 [00:05<00:05,  2.39it/s]epoch 4 loss 0.57196:  52%|█████▏    | 14/27 [00:05<00:05,  2.30it/s]epoch 4 loss 0.56444:  52%|█████▏    | 14/27 [00:06<00:05,  2.30it/s]epoch 4 loss 0.56444:  56%|█████▌    | 15/27 [00:06<00:05,  2.37it/s]epoch 4 loss 0.57504:  56%|█████▌    | 15/27 [00:06<00:05,  2.37it/s]epoch 4 loss 0.57504:  59%|█████▉    | 16/27 [00:06<00:04,  2.42it/s]epoch 4 loss 0.58081:  59%|█████▉    | 16/27 [00:07<00:04,  2.42it/s]epoch 4 loss 0.58081:  63%|██████▎   | 17/27 [00:07<00:04,  2.47it/s]epoch 4 loss 0.58864:  63%|██████▎   | 17/27 [00:07<00:04,  2.47it/s]epoch 4 loss 0.58864:  67%|██████▋   | 18/27 [00:07<00:03,  2.47it/s]epoch 4 loss 0.58839:  67%|██████▋   | 18/27 [00:07<00:03,  2.47it/s]epoch 4 loss 0.58839:  70%|███████   | 19/27 [00:07<00:03,  2.37it/s]epoch 4 loss 0.58609:  70%|███████   | 19/27 [00:08<00:03,  2.37it/s]epoch 4 loss 0.58609:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 4 loss 0.59055:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 4 loss 0.59055:  78%|███████▊  | 21/27 [00:08<00:02,  2.44it/s]epoch 4 loss 0.58458:  78%|███████▊  | 21/27 [00:09<00:02,  2.44it/s]epoch 4 loss 0.58458:  81%|████████▏ | 22/27 [00:09<00:02,  2.34it/s]epoch 4 loss 0.57824:  81%|████████▏ | 22/27 [00:09<00:02,  2.34it/s]epoch 4 loss 0.57824:  85%|████████▌ | 23/27 [00:09<00:01,  2.41it/s]epoch 4 loss 0.57421:  85%|████████▌ | 23/27 [00:10<00:01,  2.41it/s]epoch 4 loss 0.57421:  89%|████████▉ | 24/27 [00:10<00:01,  2.41it/s]epoch 4 loss 0.57559:  89%|████████▉ | 24/27 [00:10<00:01,  2.41it/s]epoch 4 loss 0.57559:  93%|█████████▎| 25/27 [00:10<00:00,  2.36it/s]epoch 4 loss 0.57647:  93%|█████████▎| 25/27 [00:10<00:00,  2.36it/s]epoch 4 loss 0.57647:  96%|█████████▋| 26/27 [00:10<00:00,  2.41it/s]epoch 4 loss 0.58956:  96%|█████████▋| 26/27 [00:11<00:00,  2.41it/s]08/17/2022 17:08:13 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:08:13 - INFO - __main__ -     Num examples = 27
08/17/2022 17:08:13 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  7.15it/s][A
evaluate eval: 100%|██████████| 2/2 [00:00<00:00,  7.46it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  7.40it/s]
08/17/2022 17:08:13 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:08:13 - INFO - __main__ -     eval_f1 = 0.8182
08/17/2022 17:08:13 - INFO - __main__ -     eval_precision = 0.72
08/17/2022 17:08:13 - INFO - __main__ -     eval_recall = 0.9474
08/17/2022 17:08:13 - INFO - __main__ -     eval_threshold = 0.5
08/17/2022 17:08:13 - INFO - __main__ -     ********************
08/17/2022 17:08:13 - INFO - __main__ -     Best f1:0.8182
08/17/2022 17:08:13 - INFO - __main__ -     ********************
08/17/2022 17:08:16 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-best-f1/model.bin
epoch 4 loss 0.58956: 100%|██████████| 27/27 [00:13<00:00,  1.19s/it]epoch 4 loss 0.58956: 100%|██████████| 27/27 [00:13<00:00,  1.94it/s]
08/17/2022 17:08:18 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 5 loss 0.41619:   0%|          | 0/27 [00:00<?, ?it/s]epoch 5 loss 0.41619:   4%|▎         | 1/27 [00:00<00:10,  2.51it/s]epoch 5 loss 0.55871:   4%|▎         | 1/27 [00:00<00:10,  2.51it/s]epoch 5 loss 0.55871:   7%|▋         | 2/27 [00:00<00:09,  2.53it/s]epoch 5 loss 0.50189:   7%|▋         | 2/27 [00:01<00:09,  2.53it/s]epoch 5 loss 0.50189:  11%|█         | 3/27 [00:01<00:10,  2.35it/s]epoch 5 loss 0.48213:  11%|█         | 3/27 [00:01<00:10,  2.35it/s]epoch 5 loss 0.48213:  15%|█▍        | 4/27 [00:01<00:09,  2.39it/s]epoch 5 loss 0.50769:  15%|█▍        | 4/27 [00:02<00:09,  2.39it/s]epoch 5 loss 0.50769:  19%|█▊        | 5/27 [00:02<00:09,  2.44it/s]epoch 5 loss 0.51986:  19%|█▊        | 5/27 [00:02<00:09,  2.44it/s]epoch 5 loss 0.51986:  22%|██▏       | 6/27 [00:02<00:09,  2.31it/s]epoch 5 loss 0.51782:  22%|██▏       | 6/27 [00:02<00:09,  2.31it/s]epoch 5 loss 0.51782:  26%|██▌       | 7/27 [00:02<00:08,  2.38it/s]epoch 5 loss 0.53005:  26%|██▌       | 7/27 [00:03<00:08,  2.38it/s]epoch 5 loss 0.53005:  30%|██▉       | 8/27 [00:03<00:07,  2.41it/s]epoch 5 loss 0.53744:  30%|██▉       | 8/27 [00:03<00:07,  2.41it/s]epoch 5 loss 0.53744:  33%|███▎      | 9/27 [00:03<00:07,  2.32it/s]epoch 5 loss 0.55761:  33%|███▎      | 9/27 [00:04<00:07,  2.32it/s]epoch 5 loss 0.55761:  37%|███▋      | 10/27 [00:04<00:07,  2.38it/s]epoch 5 loss 0.54614:  37%|███▋      | 10/27 [00:04<00:07,  2.38it/s]epoch 5 loss 0.54614:  41%|████      | 11/27 [00:04<00:06,  2.42it/s]epoch 5 loss 0.55202:  41%|████      | 11/27 [00:05<00:06,  2.42it/s]epoch 5 loss 0.55202:  44%|████▍     | 12/27 [00:05<00:06,  2.32it/s]epoch 5 loss 0.54632:  44%|████▍     | 12/27 [00:05<00:06,  2.32it/s]epoch 5 loss 0.54632:  48%|████▊     | 13/27 [00:05<00:05,  2.36it/s]epoch 5 loss 0.54422:  48%|████▊     | 13/27 [00:05<00:05,  2.36it/s]epoch 5 loss 0.54422:  52%|█████▏    | 14/27 [00:05<00:05,  2.41it/s]epoch 5 loss 0.53922:  52%|█████▏    | 14/27 [00:06<00:05,  2.41it/s]epoch 5 loss 0.53922:  56%|█████▌    | 15/27 [00:06<00:05,  2.33it/s]epoch 5 loss 0.5364:  56%|█████▌    | 15/27 [00:06<00:05,  2.33it/s] epoch 5 loss 0.5364:  59%|█████▉    | 16/27 [00:06<00:04,  2.40it/s]epoch 5 loss 0.52827:  59%|█████▉    | 16/27 [00:07<00:04,  2.40it/s]epoch 5 loss 0.52827:  63%|██████▎   | 17/27 [00:07<00:04,  2.42it/s]epoch 5 loss 0.5233:  63%|██████▎   | 17/27 [00:07<00:04,  2.42it/s] epoch 5 loss 0.5233:  67%|██████▋   | 18/27 [00:07<00:03,  2.32it/s]epoch 5 loss 0.52224:  67%|██████▋   | 18/27 [00:07<00:03,  2.32it/s]epoch 5 loss 0.52224:  70%|███████   | 19/27 [00:07<00:03,  2.39it/s]epoch 5 loss 0.52238:  70%|███████   | 19/27 [00:08<00:03,  2.39it/s]epoch 5 loss 0.52238:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 5 loss 0.52272:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 5 loss 0.52272:  78%|███████▊  | 21/27 [00:08<00:02,  2.34it/s]epoch 5 loss 0.52341:  78%|███████▊  | 21/27 [00:09<00:02,  2.34it/s]epoch 5 loss 0.52341:  81%|████████▏ | 22/27 [00:09<00:02,  2.40it/s]epoch 5 loss 0.51847:  81%|████████▏ | 22/27 [00:09<00:02,  2.40it/s]epoch 5 loss 0.51847:  85%|████████▌ | 23/27 [00:09<00:01,  2.43it/s]epoch 5 loss 0.51308:  85%|████████▌ | 23/27 [00:10<00:01,  2.43it/s]epoch 5 loss 0.51308:  89%|████████▉ | 24/27 [00:10<00:01,  2.35it/s]epoch 5 loss 0.51403:  89%|████████▉ | 24/27 [00:10<00:01,  2.35it/s]epoch 5 loss 0.51403:  93%|█████████▎| 25/27 [00:10<00:00,  2.40it/s]epoch 5 loss 0.51029:  93%|█████████▎| 25/27 [00:10<00:00,  2.40it/s]epoch 5 loss 0.51029:  96%|█████████▋| 26/27 [00:10<00:00,  2.43it/s]epoch 5 loss 0.50405:  96%|█████████▋| 26/27 [00:11<00:00,  2.43it/s]08/17/2022 17:08:29 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:08:29 - INFO - __main__ -     Num examples = 27
08/17/2022 17:08:29 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.14it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.66it/s]
08/17/2022 17:08:30 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:08:30 - INFO - __main__ -     eval_f1 = 0.7097
08/17/2022 17:08:30 - INFO - __main__ -     eval_precision = 0.9167
08/17/2022 17:08:30 - INFO - __main__ -     eval_recall = 0.5789
08/17/2022 17:08:30 - INFO - __main__ -     eval_threshold = 0.5
epoch 5 loss 0.50405: 100%|██████████| 27/27 [00:11<00:00,  2.12it/s]epoch 5 loss 0.50405: 100%|██████████| 27/27 [00:11<00:00,  2.35it/s]
08/17/2022 17:08:32 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 6 loss 0.30154:   0%|          | 0/27 [00:00<?, ?it/s]epoch 6 loss 0.30154:   4%|▎         | 1/27 [00:00<00:10,  2.40it/s]epoch 6 loss 0.33883:   4%|▎         | 1/27 [00:00<00:10,  2.40it/s]epoch 6 loss 0.33883:   7%|▋         | 2/27 [00:00<00:10,  2.37it/s]epoch 6 loss 0.4073:   7%|▋         | 2/27 [00:01<00:10,  2.37it/s] epoch 6 loss 0.4073:  11%|█         | 3/27 [00:01<00:10,  2.26it/s]epoch 6 loss 0.38905:  11%|█         | 3/27 [00:01<00:10,  2.26it/s]epoch 6 loss 0.38905:  15%|█▍        | 4/27 [00:01<00:09,  2.32it/s]epoch 6 loss 0.38937:  15%|█▍        | 4/27 [00:02<00:09,  2.32it/s]epoch 6 loss 0.38937:  19%|█▊        | 5/27 [00:02<00:09,  2.38it/s]epoch 6 loss 0.39046:  19%|█▊        | 5/27 [00:02<00:09,  2.38it/s]epoch 6 loss 0.39046:  22%|██▏       | 6/27 [00:02<00:09,  2.29it/s]epoch 6 loss 0.38386:  22%|██▏       | 6/27 [00:02<00:09,  2.29it/s]epoch 6 loss 0.38386:  26%|██▌       | 7/27 [00:02<00:08,  2.36it/s]epoch 6 loss 0.37868:  26%|██▌       | 7/27 [00:03<00:08,  2.36it/s]epoch 6 loss 0.37868:  30%|██▉       | 8/27 [00:03<00:07,  2.40it/s]epoch 6 loss 0.38678:  30%|██▉       | 8/27 [00:03<00:07,  2.40it/s]epoch 6 loss 0.38678:  33%|███▎      | 9/27 [00:03<00:07,  2.34it/s]epoch 6 loss 0.40518:  33%|███▎      | 9/27 [00:04<00:07,  2.34it/s]epoch 6 loss 0.40518:  37%|███▋      | 10/27 [00:04<00:07,  2.40it/s]epoch 6 loss 0.40492:  37%|███▋      | 10/27 [00:04<00:07,  2.40it/s]epoch 6 loss 0.40492:  41%|████      | 11/27 [00:04<00:06,  2.41it/s]epoch 6 loss 0.40975:  41%|████      | 11/27 [00:05<00:06,  2.41it/s]epoch 6 loss 0.40975:  44%|████▍     | 12/27 [00:05<00:06,  2.35it/s]epoch 6 loss 0.41432:  44%|████▍     | 12/27 [00:05<00:06,  2.35it/s]epoch 6 loss 0.41432:  48%|████▊     | 13/27 [00:05<00:05,  2.40it/s]epoch 6 loss 0.4051:  48%|████▊     | 13/27 [00:05<00:05,  2.40it/s] epoch 6 loss 0.4051:  52%|█████▏    | 14/27 [00:05<00:05,  2.39it/s]epoch 6 loss 0.41203:  52%|█████▏    | 14/27 [00:06<00:05,  2.39it/s]epoch 6 loss 0.41203:  56%|█████▌    | 15/27 [00:06<00:05,  2.30it/s]epoch 6 loss 0.41134:  56%|█████▌    | 15/27 [00:06<00:05,  2.30it/s]epoch 6 loss 0.41134:  59%|█████▉    | 16/27 [00:06<00:04,  2.39it/s]epoch 6 loss 0.41088:  59%|█████▉    | 16/27 [00:07<00:04,  2.39it/s]epoch 6 loss 0.41088:  63%|██████▎   | 17/27 [00:07<00:04,  2.41it/s]epoch 6 loss 0.41683:  63%|██████▎   | 17/27 [00:07<00:04,  2.41it/s]epoch 6 loss 0.41683:  67%|██████▋   | 18/27 [00:07<00:03,  2.33it/s]epoch 6 loss 0.41241:  67%|██████▋   | 18/27 [00:08<00:03,  2.33it/s]epoch 6 loss 0.41241:  70%|███████   | 19/27 [00:08<00:03,  2.39it/s]epoch 6 loss 0.41241:  70%|███████   | 19/27 [00:08<00:03,  2.39it/s]epoch 6 loss 0.41241:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 6 loss 0.41662:  74%|███████▍  | 20/27 [00:08<00:02,  2.41it/s]epoch 6 loss 0.41662:  78%|███████▊  | 21/27 [00:08<00:02,  2.32it/s]epoch 6 loss 0.41373:  78%|███████▊  | 21/27 [00:09<00:02,  2.32it/s]epoch 6 loss 0.41373:  81%|████████▏ | 22/27 [00:09<00:02,  2.39it/s]epoch 6 loss 0.40794:  81%|████████▏ | 22/27 [00:09<00:02,  2.39it/s]epoch 6 loss 0.40794:  85%|████████▌ | 23/27 [00:09<00:01,  2.41it/s]epoch 6 loss 0.40503:  85%|████████▌ | 23/27 [00:10<00:01,  2.41it/s]epoch 6 loss 0.40503:  89%|████████▉ | 24/27 [00:10<00:01,  2.35it/s]epoch 6 loss 0.40505:  89%|████████▉ | 24/27 [00:10<00:01,  2.35it/s]epoch 6 loss 0.40505:  93%|█████████▎| 25/27 [00:10<00:00,  2.40it/s]epoch 6 loss 0.40829:  93%|█████████▎| 25/27 [00:10<00:00,  2.40it/s]epoch 6 loss 0.40829:  96%|█████████▋| 26/27 [00:10<00:00,  2.40it/s]epoch 6 loss 0.40735:  96%|█████████▋| 26/27 [00:11<00:00,  2.40it/s]08/17/2022 17:08:43 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:08:43 - INFO - __main__ -     Num examples = 27
08/17/2022 17:08:43 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.28it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.74it/s]
08/17/2022 17:08:44 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:08:44 - INFO - __main__ -     eval_f1 = 0.6667
08/17/2022 17:08:44 - INFO - __main__ -     eval_precision = 0.9091
08/17/2022 17:08:44 - INFO - __main__ -     eval_recall = 0.5263
08/17/2022 17:08:44 - INFO - __main__ -     eval_threshold = 0.5
epoch 6 loss 0.40735: 100%|██████████| 27/27 [00:11<00:00,  2.08it/s]epoch 6 loss 0.40735: 100%|██████████| 27/27 [00:11<00:00,  2.33it/s]
08/17/2022 17:08:46 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 7 loss 0.32555:   0%|          | 0/27 [00:00<?, ?it/s]epoch 7 loss 0.32555:   4%|▎         | 1/27 [00:00<00:10,  2.54it/s]epoch 7 loss 0.3004:   4%|▎         | 1/27 [00:00<00:10,  2.54it/s] epoch 7 loss 0.3004:   7%|▋         | 2/27 [00:00<00:09,  2.53it/s]epoch 7 loss 0.31568:   7%|▋         | 2/27 [00:01<00:09,  2.53it/s]epoch 7 loss 0.31568:  11%|█         | 3/27 [00:01<00:10,  2.36it/s]epoch 7 loss 0.30993:  11%|█         | 3/27 [00:01<00:10,  2.36it/s]epoch 7 loss 0.30993:  15%|█▍        | 4/27 [00:01<00:09,  2.44it/s]epoch 7 loss 0.32286:  15%|█▍        | 4/27 [00:02<00:09,  2.44it/s]epoch 7 loss 0.32286:  19%|█▊        | 5/27 [00:02<00:09,  2.44it/s]epoch 7 loss 0.34035:  19%|█▊        | 5/27 [00:02<00:09,  2.44it/s]epoch 7 loss 0.34035:  22%|██▏       | 6/27 [00:02<00:08,  2.34it/s]epoch 7 loss 0.32737:  22%|██▏       | 6/27 [00:02<00:08,  2.34it/s]epoch 7 loss 0.32737:  26%|██▌       | 7/27 [00:02<00:08,  2.41it/s]epoch 7 loss 0.3231:  26%|██▌       | 7/27 [00:03<00:08,  2.41it/s] epoch 7 loss 0.3231:  30%|██▉       | 8/27 [00:03<00:07,  2.42it/s]epoch 7 loss 0.32379:  30%|██▉       | 8/27 [00:03<00:07,  2.42it/s]epoch 7 loss 0.32379:  33%|███▎      | 9/27 [00:03<00:07,  2.35it/s]epoch 7 loss 0.30902:  33%|███▎      | 9/27 [00:04<00:07,  2.35it/s]epoch 7 loss 0.30902:  37%|███▋      | 10/27 [00:04<00:07,  2.41it/s]epoch 7 loss 0.29556:  37%|███▋      | 10/27 [00:04<00:07,  2.41it/s]epoch 7 loss 0.29556:  41%|████      | 11/27 [00:04<00:06,  2.39it/s]epoch 7 loss 0.2875:  41%|████      | 11/27 [00:05<00:06,  2.39it/s] epoch 7 loss 0.2875:  44%|████▍     | 12/27 [00:05<00:06,  2.34it/s]epoch 7 loss 0.29549:  44%|████▍     | 12/27 [00:05<00:06,  2.34it/s]epoch 7 loss 0.29549:  48%|████▊     | 13/27 [00:05<00:05,  2.38it/s]epoch 7 loss 0.30901:  48%|████▊     | 13/27 [00:05<00:05,  2.38it/s]epoch 7 loss 0.30901:  52%|█████▏    | 14/27 [00:05<00:05,  2.37it/s]epoch 7 loss 0.30022:  52%|█████▏    | 14/27 [00:06<00:05,  2.37it/s]epoch 7 loss 0.30022:  56%|█████▌    | 15/27 [00:06<00:05,  2.34it/s]epoch 7 loss 0.30283:  56%|█████▌    | 15/27 [00:06<00:05,  2.34it/s]epoch 7 loss 0.30283:  59%|█████▉    | 16/27 [00:06<00:04,  2.40it/s]epoch 7 loss 0.30301:  59%|█████▉    | 16/27 [00:07<00:04,  2.40it/s]epoch 7 loss 0.30301:  63%|██████▎   | 17/27 [00:07<00:04,  2.40it/s]epoch 7 loss 0.2957:  63%|██████▎   | 17/27 [00:07<00:04,  2.40it/s] epoch 7 loss 0.2957:  67%|██████▋   | 18/27 [00:07<00:03,  2.31it/s]epoch 7 loss 0.29259:  67%|██████▋   | 18/27 [00:07<00:03,  2.31it/s]epoch 7 loss 0.29259:  70%|███████   | 19/27 [00:07<00:03,  2.38it/s]epoch 7 loss 0.29182:  70%|███████   | 19/27 [00:08<00:03,  2.38it/s]epoch 7 loss 0.29182:  74%|███████▍  | 20/27 [00:08<00:02,  2.40it/s]epoch 7 loss 0.30304:  74%|███████▍  | 20/27 [00:08<00:02,  2.40it/s]epoch 7 loss 0.30304:  78%|███████▊  | 21/27 [00:08<00:02,  2.33it/s]epoch 7 loss 0.30987:  78%|███████▊  | 21/27 [00:09<00:02,  2.33it/s]epoch 7 loss 0.30987:  81%|████████▏ | 22/27 [00:09<00:02,  2.38it/s]epoch 7 loss 0.30656:  81%|████████▏ | 22/27 [00:09<00:02,  2.38it/s]epoch 7 loss 0.30656:  85%|████████▌ | 23/27 [00:09<00:01,  2.38it/s]epoch 7 loss 0.31128:  85%|████████▌ | 23/27 [00:10<00:01,  2.38it/s]epoch 7 loss 0.31128:  89%|████████▉ | 24/27 [00:10<00:01,  2.31it/s]epoch 7 loss 0.31513:  89%|████████▉ | 24/27 [00:10<00:01,  2.31it/s]epoch 7 loss 0.31513:  93%|█████████▎| 25/27 [00:10<00:00,  2.35it/s]epoch 7 loss 0.31769:  93%|█████████▎| 25/27 [00:10<00:00,  2.35it/s]epoch 7 loss 0.31769:  96%|█████████▋| 26/27 [00:10<00:00,  2.34it/s]epoch 7 loss 0.31597:  96%|█████████▋| 26/27 [00:11<00:00,  2.34it/s]08/17/2022 17:08:58 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:08:58 - INFO - __main__ -     Num examples = 27
08/17/2022 17:08:58 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.14it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.67it/s]
08/17/2022 17:08:58 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:08:58 - INFO - __main__ -     eval_f1 = 0.5185
08/17/2022 17:08:58 - INFO - __main__ -     eval_precision = 0.875
08/17/2022 17:08:58 - INFO - __main__ -     eval_recall = 0.3684
08/17/2022 17:08:58 - INFO - __main__ -     eval_threshold = 0.5
epoch 7 loss 0.31597: 100%|██████████| 27/27 [00:11<00:00,  2.10it/s]epoch 7 loss 0.31597: 100%|██████████| 27/27 [00:11<00:00,  2.34it/s]
08/17/2022 17:09:02 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 8 loss 0.23099:   0%|          | 0/27 [00:00<?, ?it/s]epoch 8 loss 0.23099:   4%|▎         | 1/27 [00:00<00:11,  2.36it/s]epoch 8 loss 0.26117:   4%|▎         | 1/27 [00:00<00:11,  2.36it/s]epoch 8 loss 0.26117:   7%|▋         | 2/27 [00:00<00:11,  2.25it/s]epoch 8 loss 0.25857:   7%|▋         | 2/27 [00:01<00:11,  2.25it/s]epoch 8 loss 0.25857:  11%|█         | 3/27 [00:01<00:10,  2.38it/s]epoch 8 loss 0.28504:  11%|█         | 3/27 [00:01<00:10,  2.38it/s]epoch 8 loss 0.28504:  15%|█▍        | 4/27 [00:01<00:09,  2.41it/s]epoch 8 loss 0.27595:  15%|█▍        | 4/27 [00:02<00:09,  2.41it/s]epoch 8 loss 0.27595:  19%|█▊        | 5/27 [00:02<00:09,  2.37it/s]epoch 8 loss 0.26585:  19%|█▊        | 5/27 [00:02<00:09,  2.37it/s]epoch 8 loss 0.26585:  22%|██▏       | 6/27 [00:02<00:08,  2.39it/s]epoch 8 loss 0.28849:  22%|██▏       | 6/27 [00:02<00:08,  2.39it/s]epoch 8 loss 0.28849:  26%|██▌       | 7/27 [00:02<00:08,  2.42it/s]epoch 8 loss 0.28889:  26%|██▌       | 7/27 [00:03<00:08,  2.42it/s]epoch 8 loss 0.28889:  30%|██▉       | 8/27 [00:03<00:08,  2.37it/s]epoch 8 loss 0.28143:  30%|██▉       | 8/27 [00:03<00:08,  2.37it/s]epoch 8 loss 0.28143:  33%|███▎      | 9/27 [00:03<00:07,  2.42it/s]epoch 8 loss 0.27682:  33%|███▎      | 9/27 [00:04<00:07,  2.42it/s]epoch 8 loss 0.27682:  37%|███▋      | 10/27 [00:04<00:07,  2.41it/s]epoch 8 loss 0.26689:  37%|███▋      | 10/27 [00:04<00:07,  2.41it/s]epoch 8 loss 0.26689:  41%|████      | 11/27 [00:04<00:06,  2.41it/s]epoch 8 loss 0.25698:  41%|████      | 11/27 [00:04<00:06,  2.41it/s]epoch 8 loss 0.25698:  44%|████▍     | 12/27 [00:04<00:06,  2.44it/s]epoch 8 loss 0.28075:  44%|████▍     | 12/27 [00:05<00:06,  2.44it/s]epoch 8 loss 0.28075:  48%|████▊     | 13/27 [00:05<00:05,  2.44it/s]epoch 8 loss 0.28718:  48%|████▊     | 13/27 [00:05<00:05,  2.44it/s]epoch 8 loss 0.28718:  52%|█████▏    | 14/27 [00:05<00:05,  2.40it/s]epoch 8 loss 0.28381:  52%|█████▏    | 14/27 [00:06<00:05,  2.40it/s]epoch 8 loss 0.28381:  56%|█████▌    | 15/27 [00:06<00:04,  2.44it/s]epoch 8 loss 0.27506:  56%|█████▌    | 15/27 [00:06<00:04,  2.44it/s]epoch 8 loss 0.27506:  59%|█████▉    | 16/27 [00:06<00:04,  2.44it/s]epoch 8 loss 0.27374:  59%|█████▉    | 16/27 [00:07<00:04,  2.44it/s]epoch 8 loss 0.27374:  63%|██████▎   | 17/27 [00:07<00:04,  2.42it/s]epoch 8 loss 0.27282:  63%|██████▎   | 17/27 [00:07<00:04,  2.42it/s]epoch 8 loss 0.27282:  67%|██████▋   | 18/27 [00:07<00:03,  2.46it/s]epoch 8 loss 0.27413:  67%|██████▋   | 18/27 [00:07<00:03,  2.46it/s]epoch 8 loss 0.27413:  70%|███████   | 19/27 [00:07<00:03,  2.46it/s]epoch 8 loss 0.26743:  70%|███████   | 19/27 [00:08<00:03,  2.46it/s]epoch 8 loss 0.26743:  74%|███████▍  | 20/27 [00:08<00:02,  2.43it/s]epoch 8 loss 0.26308:  74%|███████▍  | 20/27 [00:08<00:02,  2.43it/s]epoch 8 loss 0.26308:  78%|███████▊  | 21/27 [00:08<00:02,  2.47it/s]epoch 8 loss 0.25686:  78%|███████▊  | 21/27 [00:09<00:02,  2.47it/s]epoch 8 loss 0.25686:  81%|████████▏ | 22/27 [00:09<00:02,  2.45it/s]epoch 8 loss 0.25674:  81%|████████▏ | 22/27 [00:09<00:02,  2.45it/s]epoch 8 loss 0.25674:  85%|████████▌ | 23/27 [00:09<00:01,  2.43it/s]epoch 8 loss 0.25021:  85%|████████▌ | 23/27 [00:09<00:01,  2.43it/s]epoch 8 loss 0.25021:  89%|████████▉ | 24/27 [00:09<00:01,  2.48it/s]epoch 8 loss 0.24805:  89%|████████▉ | 24/27 [00:10<00:01,  2.48it/s]epoch 8 loss 0.24805:  93%|█████████▎| 25/27 [00:10<00:00,  2.47it/s]epoch 8 loss 0.24687:  93%|█████████▎| 25/27 [00:10<00:00,  2.47it/s]epoch 8 loss 0.24687:  96%|█████████▋| 26/27 [00:10<00:00,  2.45it/s]epoch 8 loss 0.25006:  96%|█████████▋| 26/27 [00:11<00:00,  2.45it/s]08/17/2022 17:09:13 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:09:13 - INFO - __main__ -     Num examples = 27
08/17/2022 17:09:13 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.17it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.49it/s]
08/17/2022 17:09:13 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:09:13 - INFO - __main__ -     eval_f1 = 0.6667
08/17/2022 17:09:13 - INFO - __main__ -     eval_precision = 0.9091
08/17/2022 17:09:13 - INFO - __main__ -     eval_recall = 0.5263
08/17/2022 17:09:13 - INFO - __main__ -     eval_threshold = 0.5
epoch 8 loss 0.25006: 100%|██████████| 27/27 [00:11<00:00,  2.21it/s]epoch 8 loss 0.25006: 100%|██████████| 27/27 [00:11<00:00,  2.39it/s]
08/17/2022 17:09:17 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
  0%|          | 0/27 [00:00<?, ?it/s]epoch 9 loss 0.28468:   0%|          | 0/27 [00:00<?, ?it/s]epoch 9 loss 0.28468:   4%|▎         | 1/27 [00:00<00:09,  2.61it/s]epoch 9 loss 0.25173:   4%|▎         | 1/27 [00:00<00:09,  2.61it/s]epoch 9 loss 0.25173:   7%|▋         | 2/27 [00:00<00:10,  2.49it/s]epoch 9 loss 0.25436:   7%|▋         | 2/27 [00:01<00:10,  2.49it/s]epoch 9 loss 0.25436:  11%|█         | 3/27 [00:01<00:10,  2.37it/s]epoch 9 loss 0.2252:  11%|█         | 3/27 [00:01<00:10,  2.37it/s] epoch 9 loss 0.2252:  15%|█▍        | 4/27 [00:01<00:09,  2.46it/s]epoch 9 loss 0.21247:  15%|█▍        | 4/27 [00:02<00:09,  2.46it/s]epoch 9 loss 0.21247:  19%|█▊        | 5/27 [00:02<00:08,  2.45it/s]epoch 9 loss 0.20645:  19%|█▊        | 5/27 [00:02<00:08,  2.45it/s]epoch 9 loss 0.20645:  22%|██▏       | 6/27 [00:02<00:08,  2.34it/s]epoch 9 loss 0.1938:  22%|██▏       | 6/27 [00:02<00:08,  2.34it/s] epoch 9 loss 0.1938:  26%|██▌       | 7/27 [00:02<00:08,  2.41it/s]epoch 9 loss 0.19479:  26%|██▌       | 7/27 [00:03<00:08,  2.41it/s]epoch 9 loss 0.19479:  30%|██▉       | 8/27 [00:03<00:07,  2.43it/s]epoch 9 loss 0.19221:  30%|██▉       | 8/27 [00:03<00:07,  2.43it/s]epoch 9 loss 0.19221:  33%|███▎      | 9/27 [00:03<00:07,  2.33it/s]epoch 9 loss 0.19894:  33%|███▎      | 9/27 [00:04<00:07,  2.33it/s]epoch 9 loss 0.19894:  37%|███▋      | 10/27 [00:04<00:07,  2.39it/s]epoch 9 loss 0.19024:  37%|███▋      | 10/27 [00:04<00:07,  2.39it/s]epoch 9 loss 0.19024:  41%|████      | 11/27 [00:04<00:06,  2.42it/s]epoch 9 loss 0.18877:  41%|████      | 11/27 [00:05<00:06,  2.42it/s]epoch 9 loss 0.18877:  44%|████▍     | 12/27 [00:05<00:06,  2.32it/s]epoch 9 loss 0.18616:  44%|████▍     | 12/27 [00:05<00:06,  2.32it/s]epoch 9 loss 0.18616:  48%|████▊     | 13/27 [00:05<00:05,  2.39it/s]epoch 9 loss 0.18661:  48%|████▊     | 13/27 [00:05<00:05,  2.39it/s]epoch 9 loss 0.18661:  52%|█████▏    | 14/27 [00:05<00:05,  2.42it/s]epoch 9 loss 0.18359:  52%|█████▏    | 14/27 [00:06<00:05,  2.42it/s]epoch 9 loss 0.18359:  56%|█████▌    | 15/27 [00:06<00:05,  2.34it/s]epoch 9 loss 0.18466:  56%|█████▌    | 15/27 [00:06<00:05,  2.34it/s]epoch 9 loss 0.18466:  59%|█████▉    | 16/27 [00:06<00:04,  2.38it/s]epoch 9 loss 0.19017:  59%|█████▉    | 16/27 [00:07<00:04,  2.38it/s]epoch 9 loss 0.19017:  63%|██████▎   | 17/27 [00:07<00:04,  2.41it/s]epoch 9 loss 0.20143:  63%|██████▎   | 17/27 [00:07<00:04,  2.41it/s]epoch 9 loss 0.20143:  67%|██████▋   | 18/27 [00:07<00:03,  2.34it/s]epoch 9 loss 0.19682:  67%|██████▋   | 18/27 [00:07<00:03,  2.34it/s]epoch 9 loss 0.19682:  70%|███████   | 19/27 [00:07<00:03,  2.41it/s]epoch 9 loss 0.1983:  70%|███████   | 19/27 [00:08<00:03,  2.41it/s] epoch 9 loss 0.1983:  74%|███████▍  | 20/27 [00:08<00:02,  2.43it/s]epoch 9 loss 0.19672:  74%|███████▍  | 20/27 [00:08<00:02,  2.43it/s]epoch 9 loss 0.19672:  78%|███████▊  | 21/27 [00:08<00:02,  2.35it/s]epoch 9 loss 0.1943:  78%|███████▊  | 21/27 [00:09<00:02,  2.35it/s] epoch 9 loss 0.1943:  81%|████████▏ | 22/27 [00:09<00:02,  2.41it/s]epoch 9 loss 0.19649:  81%|████████▏ | 22/27 [00:09<00:02,  2.41it/s]epoch 9 loss 0.19649:  85%|████████▌ | 23/27 [00:09<00:01,  2.40it/s]epoch 9 loss 0.19604:  85%|████████▌ | 23/27 [00:10<00:01,  2.40it/s]epoch 9 loss 0.19604:  89%|████████▉ | 24/27 [00:10<00:01,  2.36it/s]epoch 9 loss 0.19149:  89%|████████▉ | 24/27 [00:10<00:01,  2.36it/s]epoch 9 loss 0.19149:  93%|█████████▎| 25/27 [00:10<00:00,  2.39it/s]epoch 9 loss 0.19423:  93%|█████████▎| 25/27 [00:10<00:00,  2.39it/s]epoch 9 loss 0.19423:  96%|█████████▋| 26/27 [00:10<00:00,  2.40it/s]epoch 9 loss 0.20546:  96%|█████████▋| 26/27 [00:11<00:00,  2.40it/s]08/17/2022 17:09:28 - INFO - __main__ -   ***** Running evaluation *****
08/17/2022 17:09:28 - INFO - __main__ -     Num examples = 27
08/17/2022 17:09:28 - INFO - __main__ -     Batch size = 16

evaluate eval:   0%|          | 0/2 [00:00<?, ?it/s][A
evaluate eval:  50%|█████     | 1/2 [00:00<00:00,  8.52it/s][Aevaluate eval: 100%|██████████| 2/2 [00:00<00:00,  9.89it/s]
08/17/2022 17:09:28 - INFO - __main__ -   ***** Eval results *****
08/17/2022 17:09:28 - INFO - __main__ -     eval_f1 = 0.6207
08/17/2022 17:09:28 - INFO - __main__ -     eval_precision = 0.9
08/17/2022 17:09:28 - INFO - __main__ -     eval_recall = 0.4737
08/17/2022 17:09:28 - INFO - __main__ -     eval_threshold = 0.5
epoch 9 loss 0.20546: 100%|██████████| 27/27 [00:11<00:00,  2.13it/s]epoch 9 loss 0.20546: 100%|██████████| 27/27 [00:11<00:00,  2.36it/s]
08/17/2022 17:09:31 - INFO - __main__ -   Saving model checkpoint to ./saved_models/dataset_size/balanced_0.01/checkpoint-last/model.bin
load dataset:   0%|          | 0/3745 [00:00<?, ?it/s]load dataset:   1%|▏         | 56/3745 [00:00<00:08, 435.11it/s]load dataset:   3%|▎         | 100/3745 [00:00<00:19, 183.59it/s]load dataset:   3%|▎         | 126/3745 [00:00<00:24, 144.88it/s]load dataset:   4%|▍         | 167/3745 [00:00<00:18, 196.83it/s]load dataset:   6%|▌         | 208/3745 [00:00<00:14, 243.36it/s]load dataset:   6%|▋         | 240/3745 [00:01<00:14, 233.68it/s]load dataset:   7%|▋         | 269/3745 [00:01<00:14, 233.09it/s]load dataset:   8%|▊         | 296/3745 [00:01<00:14, 238.78it/s]load dataset:   9%|▉         | 331/3745 [00:01<00:12, 265.59it/s]load dataset:  10%|▉         | 360/3745 [00:01<00:14, 238.66it/s]load dataset:  10%|█         | 386/3745 [00:01<00:16, 199.38it/s]load dataset:  11%|█         | 409/3745 [00:01<00:18, 178.68it/s]load dataset:  11%|█▏        | 429/3745 [00:02<00:19, 173.88it/s]load dataset:  12%|█▏        | 448/3745 [00:02<00:20, 163.73it/s]load dataset:  12%|█▏        | 466/3745 [00:02<00:19, 167.09it/s]load dataset:  13%|█▎        | 489/3745 [00:02<00:17, 182.61it/s]load dataset:  14%|█▎        | 509/3745 [00:02<00:18, 174.33it/s]load dataset:  14%|█▍        | 527/3745 [00:02<00:18, 175.76it/s]load dataset:  15%|█▍        | 556/3745 [00:02<00:16, 197.57it/s]load dataset:  15%|█▌        | 577/3745 [00:02<00:21, 148.36it/s]load dataset:  16%|█▌        | 597/3745 [00:03<00:19, 158.85it/s]load dataset:  17%|█▋        | 633/3745 [00:03<00:15, 205.76it/s]load dataset:  18%|█▊        | 682/3745 [00:03<00:11, 271.96it/s]load dataset:  19%|█▉        | 722/3745 [00:03<00:09, 303.02it/s]load dataset:  21%|██        | 771/3745 [00:03<00:08, 352.98it/s]load dataset:  22%|██▏       | 819/3745 [00:03<00:07, 387.14it/s]load dataset:  23%|██▎       | 860/3745 [00:03<00:07, 373.39it/s]load dataset:  24%|██▍       | 899/3745 [00:03<00:08, 338.82it/s]load dataset:  25%|██▌       | 944/3745 [00:03<00:07, 361.97it/s]load dataset:  26%|██▌       | 982/3745 [00:04<00:07, 350.52it/s]load dataset:  27%|██▋       | 1018/3745 [00:04<00:09, 300.37it/s]load dataset:  28%|██▊       | 1050/3745 [00:04<00:09, 271.49it/s]load dataset:  29%|██▉       | 1094/3745 [00:04<00:08, 308.67it/s]load dataset:  30%|███       | 1135/3745 [00:04<00:07, 332.88it/s]load dataset:  31%|███▏      | 1172/3745 [00:04<00:07, 339.62it/s]load dataset:  32%|███▏      | 1210/3745 [00:04<00:07, 347.22it/s]load dataset:  33%|███▎      | 1250/3745 [00:04<00:06, 361.22it/s]load dataset:  35%|███▍      | 1294/3745 [00:05<00:06, 382.46it/s]load dataset:  36%|███▌      | 1336/3745 [00:05<00:06, 383.94it/s]load dataset:  37%|███▋      | 1376/3745 [00:05<00:06, 367.14it/s]load dataset:  38%|███▊      | 1414/3745 [00:05<00:06, 351.97it/s]load dataset:  39%|███▉      | 1466/3745 [00:05<00:05, 394.35it/s]load dataset:  40%|████      | 1506/3745 [00:05<00:05, 379.58it/s]load dataset:  42%|████▏     | 1559/3745 [00:05<00:05, 420.36it/s]load dataset:  43%|████▎     | 1602/3745 [00:05<00:05, 413.62it/s]load dataset:  44%|████▍     | 1644/3745 [00:05<00:05, 404.25it/s]load dataset:  45%|████▌     | 1693/3745 [00:06<00:04, 428.45it/s]load dataset:  46%|████▋     | 1737/3745 [00:06<00:05, 339.64it/s]load dataset:  47%|████▋     | 1778/3745 [00:06<00:05, 350.56it/s]load dataset:  48%|████▊     | 1816/3745 [00:06<00:05, 329.28it/s]load dataset:  49%|████▉     | 1853/3745 [00:06<00:05, 333.57it/s]load dataset:  50%|█████     | 1889/3745 [00:06<00:05, 340.08it/s]load dataset:  51%|█████▏    | 1924/3745 [00:06<00:05, 324.63it/s]load dataset:  52%|█████▏    | 1958/3745 [00:06<00:05, 321.28it/s]load dataset:  53%|█████▎    | 1991/3745 [00:06<00:05, 313.02it/s]load dataset:  54%|█████▍    | 2025/3745 [00:07<00:05, 319.79it/s]load dataset:  55%|█████▌    | 2067/3745 [00:07<00:04, 347.30it/s]load dataset:  57%|█████▋    | 2117/3745 [00:07<00:04, 390.61it/s]load dataset:  58%|█████▊    | 2157/3745 [00:07<00:04, 352.55it/s]load dataset:  59%|█████▉    | 2203/3745 [00:07<00:04, 378.03it/s]load dataset:  60%|██████    | 2248/3745 [00:07<00:03, 392.85it/s]load dataset:  61%|██████    | 2288/3745 [00:07<00:03, 383.02it/s]load dataset:  62%|██████▏   | 2327/3745 [00:07<00:03, 379.83it/s]load dataset:  63%|██████▎   | 2368/3745 [00:07<00:03, 385.24it/s]load dataset:  64%|██████▍   | 2409/3745 [00:08<00:03, 389.44it/s]load dataset:  66%|██████▌   | 2460/3745 [00:08<00:03, 421.71it/s]load dataset:  67%|██████▋   | 2503/3745 [00:08<00:02, 422.47it/s]load dataset:  68%|██████▊   | 2551/3745 [00:08<00:02, 416.44it/s]load dataset:  69%|██████▉   | 2596/3745 [00:08<00:02, 425.14it/s]load dataset:  70%|███████   | 2639/3745 [00:08<00:02, 388.55it/s]load dataset:  72%|███████▏  | 2682/3745 [00:08<00:02, 386.19it/s]load dataset:  73%|███████▎  | 2722/3745 [00:08<00:03, 331.04it/s]load dataset:  74%|███████▍  | 2770/3745 [00:09<00:02, 366.13it/s]load dataset:  75%|███████▌  | 2809/3745 [00:09<00:02, 339.66it/s]load dataset:  76%|███████▌  | 2845/3745 [00:09<00:02, 340.70it/s]load dataset:  77%|███████▋  | 2881/3745 [00:09<00:02, 335.45it/s]load dataset:  78%|███████▊  | 2929/3745 [00:09<00:02, 373.51it/s]load dataset:  79%|███████▉  | 2968/3745 [00:09<00:02, 348.74it/s]load dataset:  80%|████████  | 3004/3745 [00:09<00:02, 285.51it/s]load dataset:  81%|████████  | 3035/3745 [00:09<00:02, 270.19it/s]load dataset:  82%|████████▏ | 3089/3745 [00:10<00:01, 334.05it/s]load dataset:  84%|████████▎ | 3133/3745 [00:10<00:01, 356.92it/s]load dataset:  85%|████████▍ | 3177/3745 [00:10<00:01, 377.85it/s]load dataset:  86%|████████▌ | 3217/3745 [00:10<00:01, 360.58it/s]load dataset:  87%|████████▋ | 3265/3745 [00:10<00:01, 390.06it/s]load dataset:  88%|████████▊ | 3307/3745 [00:10<00:01, 392.20it/s]load dataset:  90%|████████▉ | 3354/3745 [00:10<00:01, 378.79it/s]load dataset:  91%|█████████ | 3398/3745 [00:10<00:00, 392.09it/s]load dataset:  92%|█████████▏| 3443/3745 [00:10<00:00, 407.98it/s]load dataset:  93%|█████████▎| 3485/3745 [00:11<00:00, 364.99it/s]load dataset:  94%|█████████▍| 3523/3745 [00:11<00:00, 339.19it/s]load dataset:  95%|█████████▌| 3570/3745 [00:11<00:00, 372.59it/s]load dataset:  97%|█████████▋| 3616/3745 [00:11<00:00, 391.78it/s]load dataset:  98%|█████████▊| 3661/3745 [00:11<00:00, 403.39it/s]load dataset:  99%|█████████▉| 3703/3745 [00:11<00:00, 394.25it/s]load dataset: 100%|██████████| 3745/3745 [00:11<00:00, 390.64it/s]load dataset: 100%|██████████| 3745/3745 [00:11<00:00, 320.33it/s]
08/17/2022 17:09:44 - INFO - __main__ -   ***** Running Test *****
08/17/2022 17:09:44 - INFO - __main__ -     Num examples = 3745
08/17/2022 17:09:44 - INFO - __main__ -     Batch size = 16
evaluate test:   0%|          | 0/235 [00:00<?, ?it/s]evaluate test:   0%|          | 1/235 [00:00<00:27,  8.38it/s]evaluate test:   1%|          | 2/235 [00:00<00:27,  8.41it/s]evaluate test:   1%|▏         | 3/235 [00:00<00:28,  8.05it/s]evaluate test:   2%|▏         | 4/235 [00:00<00:29,  7.90it/s]evaluate test:   2%|▏         | 5/235 [00:00<00:29,  7.68it/s]evaluate test:   3%|▎         | 6/235 [00:00<00:30,  7.46it/s]evaluate test:   3%|▎         | 7/235 [00:00<00:32,  6.94it/s]evaluate test:   3%|▎         | 8/235 [00:01<00:30,  7.33it/s]evaluate test:   4%|▍         | 9/235 [00:01<00:29,  7.62it/s]evaluate test:   4%|▍         | 10/235 [00:01<00:28,  7.87it/s]evaluate test:   5%|▍         | 11/235 [00:01<00:28,  7.99it/s]evaluate test:   5%|▌         | 12/235 [00:01<00:27,  8.10it/s]evaluate test:   6%|▌         | 13/235 [00:01<00:27,  8.08it/s]evaluate test:   6%|▌         | 14/235 [00:01<00:28,  7.89it/s]evaluate test:   6%|▋         | 15/235 [00:01<00:28,  7.71it/s]evaluate test:   7%|▋         | 16/235 [00:02<00:29,  7.47it/s]evaluate test:   7%|▋         | 17/235 [00:02<00:30,  7.12it/s]evaluate test:   8%|▊         | 18/235 [00:02<00:29,  7.44it/s]evaluate test:   8%|▊         | 19/235 [00:02<00:28,  7.71it/s]evaluate test:   9%|▊         | 20/235 [00:02<00:27,  7.91it/s]evaluate test:   9%|▉         | 21/235 [00:02<00:26,  8.02it/s]evaluate test:   9%|▉         | 22/235 [00:02<00:26,  8.11it/s]evaluate test:  10%|▉         | 23/235 [00:02<00:26,  7.99it/s]evaluate test:  10%|█         | 24/235 [00:03<00:26,  7.85it/s]evaluate test:  11%|█         | 25/235 [00:03<00:27,  7.65it/s]evaluate test:  11%|█         | 26/235 [00:03<00:29,  7.04it/s]evaluate test:  11%|█▏        | 27/235 [00:03<00:28,  7.28it/s]evaluate test:  12%|█▏        | 28/235 [00:03<00:27,  7.55it/s]evaluate test:  12%|█▏        | 29/235 [00:03<00:26,  7.73it/s]evaluate test:  13%|█▎        | 30/235 [00:03<00:26,  7.84it/s]evaluate test:  13%|█▎        | 31/235 [00:04<00:25,  7.96it/s]evaluate test:  14%|█▎        | 32/235 [00:04<00:25,  8.05it/s]evaluate test:  14%|█▍        | 33/235 [00:04<00:25,  7.98it/s]evaluate test:  14%|█▍        | 34/235 [00:04<00:25,  7.84it/s]evaluate test:  15%|█▍        | 35/235 [00:04<00:26,  7.44it/s]evaluate test:  15%|█▌        | 36/235 [00:04<00:28,  6.88it/s]evaluate test:  16%|█▌        | 37/235 [00:04<00:27,  7.16it/s]evaluate test:  16%|█▌        | 38/235 [00:04<00:26,  7.51it/s]evaluate test:  17%|█▋        | 39/235 [00:05<00:25,  7.76it/s]evaluate test:  17%|█▋        | 40/235 [00:05<00:24,  7.94it/s]evaluate test:  17%|█▋        | 41/235 [00:05<00:24,  8.08it/s]evaluate test:  18%|█▊        | 42/235 [00:05<00:23,  8.07it/s]evaluate test:  18%|█▊        | 43/235 [00:05<00:24,  7.91it/s]evaluate test:  19%|█▊        | 44/235 [00:05<00:24,  7.68it/s]evaluate test:  19%|█▉        | 45/235 [00:05<00:26,  7.12it/s]evaluate test:  20%|█▉        | 46/235 [00:06<00:25,  7.41it/s]evaluate test:  20%|██        | 47/235 [00:06<00:24,  7.69it/s]evaluate test:  20%|██        | 48/235 [00:06<00:23,  7.88it/s]evaluate test:  21%|██        | 49/235 [00:06<00:23,  8.07it/s]evaluate test:  21%|██▏       | 50/235 [00:06<00:22,  8.16it/s]evaluate test:  22%|██▏       | 51/235 [00:06<00:22,  8.03it/s]evaluate test:  22%|██▏       | 52/235 [00:06<00:23,  7.91it/s]evaluate test:  23%|██▎       | 53/235 [00:06<00:23,  7.68it/s]evaluate test:  23%|██▎       | 54/235 [00:07<00:25,  7.04it/s]evaluate test:  23%|██▎       | 55/235 [00:07<00:24,  7.24it/s]evaluate test:  24%|██▍       | 56/235 [00:07<00:24,  7.41it/s]evaluate test:  24%|██▍       | 57/235 [00:07<00:23,  7.55it/s]evaluate test:  25%|██▍       | 58/235 [00:07<00:22,  7.72it/s]evaluate test:  25%|██▌       | 59/235 [00:07<00:22,  7.83it/s]evaluate test:  26%|██▌       | 60/235 [00:07<00:22,  7.88it/s]evaluate test:  26%|██▌       | 61/235 [00:07<00:21,  7.91it/s]evaluate test:  26%|██▋       | 62/235 [00:08<00:22,  7.79it/s]evaluate test:  27%|██▋       | 63/235 [00:08<00:22,  7.68it/s]evaluate test:  27%|██▋       | 64/235 [00:08<00:23,  7.39it/s]evaluate test:  28%|██▊       | 65/235 [00:08<00:25,  6.80it/s]evaluate test:  28%|██▊       | 66/235 [00:08<00:23,  7.05it/s]evaluate test:  29%|██▊       | 67/235 [00:08<00:22,  7.35it/s]evaluate test:  29%|██▉       | 68/235 [00:08<00:22,  7.52it/s]evaluate test:  29%|██▉       | 69/235 [00:09<00:21,  7.74it/s]evaluate test:  30%|██▉       | 70/235 [00:09<00:21,  7.78it/s]evaluate test:  30%|███       | 71/235 [00:09<00:20,  7.83it/s]evaluate test:  31%|███       | 72/235 [00:09<00:20,  7.79it/s]evaluate test:  31%|███       | 73/235 [00:09<00:21,  7.64it/s]evaluate test:  31%|███▏      | 74/235 [00:09<00:21,  7.45it/s]evaluate test:  32%|███▏      | 75/235 [00:09<00:22,  7.06it/s]evaluate test:  32%|███▏      | 76/235 [00:09<00:22,  7.02it/s]evaluate test:  33%|███▎      | 77/235 [00:10<00:21,  7.27it/s]evaluate test:  33%|███▎      | 78/235 [00:10<00:20,  7.52it/s]evaluate test:  34%|███▎      | 79/235 [00:10<00:20,  7.66it/s]evaluate test:  34%|███▍      | 80/235 [00:10<00:20,  7.71it/s]evaluate test:  34%|███▍      | 81/235 [00:10<00:19,  7.89it/s]evaluate test:  35%|███▍      | 82/235 [00:10<00:19,  7.87it/s]evaluate test:  35%|███▌      | 83/235 [00:10<00:19,  7.68it/s]evaluate test:  36%|███▌      | 84/235 [00:11<00:19,  7.55it/s]evaluate test:  36%|███▌      | 85/235 [00:11<00:20,  7.46it/s]evaluate test:  37%|███▋      | 86/235 [00:11<00:21,  7.09it/s]evaluate test:  37%|███▋      | 87/235 [00:11<00:19,  7.41it/s]evaluate test:  37%|███▋      | 88/235 [00:11<00:19,  7.68it/s]evaluate test:  38%|███▊      | 89/235 [00:11<00:18,  7.86it/s]evaluate test:  38%|███▊      | 90/235 [00:11<00:18,  7.90it/s]evaluate test:  39%|███▊      | 91/235 [00:11<00:18,  7.99it/s]evaluate test:  39%|███▉      | 92/235 [00:12<00:18,  7.91it/s]evaluate test:  40%|███▉      | 93/235 [00:12<00:18,  7.75it/s]evaluate test:  40%|████      | 94/235 [00:12<00:18,  7.64it/s]evaluate test:  40%|████      | 95/235 [00:12<00:18,  7.40it/s]evaluate test:  41%|████      | 96/235 [00:12<00:20,  6.78it/s]evaluate test:  41%|████▏     | 97/235 [00:12<00:19,  7.22it/s]evaluate test:  42%|████▏     | 98/235 [00:12<00:18,  7.46it/s]evaluate test:  42%|████▏     | 99/235 [00:12<00:17,  7.72it/s]evaluate test:  43%|████▎     | 100/235 [00:13<00:17,  7.85it/s]evaluate test:  43%|████▎     | 101/235 [00:13<00:17,  7.87it/s]evaluate test:  43%|████▎     | 102/235 [00:13<00:16,  7.85it/s]evaluate test:  44%|████▍     | 103/235 [00:13<00:17,  7.74it/s]evaluate test:  44%|████▍     | 104/235 [00:13<00:17,  7.67it/s]evaluate test:  45%|████▍     | 105/235 [00:13<00:17,  7.52it/s]evaluate test:  45%|████▌     | 106/235 [00:13<00:17,  7.36it/s]evaluate test:  46%|████▌     | 107/235 [00:14<00:18,  6.93it/s]evaluate test:  46%|████▌     | 108/235 [00:14<00:17,  7.21it/s]evaluate test:  46%|████▋     | 109/235 [00:14<00:16,  7.52it/s]evaluate test:  47%|████▋     | 110/235 [00:14<00:16,  7.72it/s]evaluate test:  47%|████▋     | 111/235 [00:14<00:15,  7.80it/s]evaluate test:  48%|████▊     | 112/235 [00:14<00:15,  7.92it/s]evaluate test:  48%|████▊     | 113/235 [00:14<00:15,  7.98it/s]evaluate test:  49%|████▊     | 114/235 [00:14<00:15,  7.82it/s]evaluate test:  49%|████▉     | 115/235 [00:15<00:15,  7.66it/s]evaluate test:  49%|████▉     | 116/235 [00:15<00:15,  7.48it/s]evaluate test:  50%|████▉     | 117/235 [00:15<00:16,  7.29it/s]evaluate test:  50%|█████     | 118/235 [00:15<00:16,  6.89it/s]evaluate test:  51%|█████     | 119/235 [00:15<00:16,  7.17it/s]evaluate test:  51%|█████     | 120/235 [00:15<00:15,  7.35it/s]evaluate test:  51%|█████▏    | 121/235 [00:15<00:15,  7.58it/s]evaluate test:  52%|█████▏    | 122/235 [00:16<00:14,  7.80it/s]evaluate test:  52%|█████▏    | 123/235 [00:16<00:14,  7.82it/s]evaluate test:  53%|█████▎    | 124/235 [00:16<00:14,  7.66it/s]evaluate test:  53%|█████▎    | 125/235 [00:16<00:14,  7.43it/s]evaluate test:  54%|█████▎    | 126/235 [00:16<00:15,  7.21it/s]evaluate test:  54%|█████▍    | 127/235 [00:16<00:15,  7.01it/s]evaluate test:  54%|█████▍    | 128/235 [00:16<00:14,  7.37it/s]evaluate test:  55%|█████▍    | 129/235 [00:16<00:13,  7.63it/s]evaluate test:  55%|█████▌    | 130/235 [00:17<00:13,  7.83it/s]evaluate test:  56%|█████▌    | 131/235 [00:17<00:13,  7.89it/s]evaluate test:  56%|█████▌    | 132/235 [00:17<00:12,  8.01it/s]evaluate test:  57%|█████▋    | 133/235 [00:17<00:12,  7.93it/s]evaluate test:  57%|█████▋    | 134/235 [00:17<00:12,  7.79it/s]evaluate test:  57%|█████▋    | 135/235 [00:17<00:13,  7.62it/s]evaluate test:  58%|█████▊    | 136/235 [00:17<00:14,  7.05it/s]evaluate test:  58%|█████▊    | 137/235 [00:18<00:13,  7.42it/s]evaluate test:  59%|█████▊    | 138/235 [00:18<00:12,  7.61it/s]evaluate test:  59%|█████▉    | 139/235 [00:18<00:12,  7.79it/s]evaluate test:  60%|█████▉    | 140/235 [00:18<00:11,  7.95it/s]evaluate test:  60%|██████    | 141/235 [00:18<00:11,  7.96it/s]evaluate test:  60%|██████    | 142/235 [00:18<00:11,  7.92it/s]evaluate test:  61%|██████    | 143/235 [00:18<00:11,  7.74it/s]evaluate test:  61%|██████▏   | 144/235 [00:18<00:12,  7.47it/s]evaluate test:  62%|██████▏   | 145/235 [00:19<00:12,  7.25it/s]evaluate test:  62%|██████▏   | 146/235 [00:19<00:12,  6.88it/s]evaluate test:  63%|██████▎   | 147/235 [00:19<00:12,  7.26it/s]evaluate test:  63%|██████▎   | 148/235 [00:19<00:12,  7.24it/s]evaluate test:  63%|██████▎   | 149/235 [00:19<00:11,  7.20it/s]evaluate test:  64%|██████▍   | 150/235 [00:19<00:11,  7.46it/s]evaluate test:  64%|██████▍   | 151/235 [00:19<00:10,  7.73it/s]evaluate test:  65%|██████▍   | 152/235 [00:20<00:10,  7.77it/s]evaluate test:  65%|██████▌   | 153/235 [00:20<00:10,  7.68it/s]evaluate test:  66%|██████▌   | 154/235 [00:20<00:10,  7.55it/s]evaluate test:  66%|██████▌   | 155/235 [00:20<00:10,  7.32it/s]evaluate test:  66%|██████▋   | 156/235 [00:20<00:11,  6.80it/s]evaluate test:  67%|██████▋   | 157/235 [00:20<00:11,  6.95it/s]evaluate test:  67%|██████▋   | 158/235 [00:20<00:10,  7.18it/s]evaluate test:  68%|██████▊   | 159/235 [00:20<00:10,  7.35it/s]evaluate test:  68%|██████▊   | 160/235 [00:21<00:09,  7.53it/s]evaluate test:  69%|██████▊   | 161/235 [00:21<00:09,  7.62it/s]evaluate test:  69%|██████▉   | 162/235 [00:21<00:09,  7.61it/s]evaluate test:  69%|██████▉   | 163/235 [00:21<00:09,  7.59it/s]evaluate test:  70%|██████▉   | 164/235 [00:21<00:09,  7.40it/s]evaluate test:  70%|███████   | 165/235 [00:21<00:10,  6.91it/s]evaluate test:  71%|███████   | 166/235 [00:21<00:09,  7.10it/s]evaluate test:  71%|███████   | 167/235 [00:22<00:09,  7.37it/s]evaluate test:  71%|███████▏  | 168/235 [00:22<00:08,  7.59it/s]evaluate test:  72%|███████▏  | 169/235 [00:22<00:08,  7.66it/s]evaluate test:  72%|███████▏  | 170/235 [00:22<00:08,  7.83it/s]evaluate test:  73%|███████▎  | 171/235 [00:22<00:08,  7.81it/s]evaluate test:  73%|███████▎  | 172/235 [00:22<00:08,  7.66it/s]evaluate test:  74%|███████▎  | 173/235 [00:22<00:08,  7.52it/s]evaluate test:  74%|███████▍  | 174/235 [00:22<00:08,  7.31it/s]evaluate test:  74%|███████▍  | 175/235 [00:23<00:08,  6.78it/s]evaluate test:  75%|███████▍  | 176/235 [00:23<00:08,  7.09it/s]evaluate test:  75%|███████▌  | 177/235 [00:23<00:07,  7.35it/s]evaluate test:  76%|███████▌  | 178/235 [00:23<00:07,  7.61it/s]evaluate test:  76%|███████▌  | 179/235 [00:23<00:07,  7.80it/s]evaluate test:  77%|███████▋  | 180/235 [00:23<00:06,  7.93it/s]evaluate test:  77%|███████▋  | 181/235 [00:23<00:06,  7.85it/s]evaluate test:  77%|███████▋  | 182/235 [00:24<00:06,  7.77it/s]evaluate test:  78%|███████▊  | 183/235 [00:24<00:06,  7.56it/s]evaluate test:  78%|███████▊  | 184/235 [00:24<00:07,  6.90it/s]evaluate test:  79%|███████▊  | 185/235 [00:24<00:07,  6.84it/s]evaluate test:  79%|███████▉  | 186/235 [00:24<00:06,  7.06it/s]evaluate test:  80%|███████▉  | 187/235 [00:24<00:06,  7.37it/s]evaluate test:  80%|████████  | 188/235 [00:24<00:06,  7.65it/s]evaluate test:  80%|████████  | 189/235 [00:24<00:05,  7.73it/s]evaluate test:  81%|████████  | 190/235 [00:25<00:05,  7.79it/s]evaluate test:  81%|████████▏ | 191/235 [00:25<00:05,  7.75it/s]evaluate test:  82%|████████▏ | 192/235 [00:25<00:05,  7.61it/s]evaluate test:  82%|████████▏ | 193/235 [00:25<00:05,  7.57it/s]evaluate test:  83%|████████▎ | 194/235 [00:25<00:05,  7.42it/s]evaluate test:  83%|████████▎ | 195/235 [00:25<00:05,  6.93it/s]evaluate test:  83%|████████▎ | 196/235 [00:25<00:05,  7.32it/s]evaluate test:  84%|████████▍ | 197/235 [00:26<00:05,  7.56it/s]evaluate test:  84%|████████▍ | 198/235 [00:26<00:04,  7.70it/s]evaluate test:  85%|████████▍ | 199/235 [00:26<00:04,  7.77it/s]evaluate test:  85%|████████▌ | 200/235 [00:26<00:04,  7.74it/s]evaluate test:  86%|████████▌ | 201/235 [00:26<00:04,  7.68it/s]evaluate test:  86%|████████▌ | 202/235 [00:26<00:04,  7.54it/s]evaluate test:  86%|████████▋ | 203/235 [00:26<00:04,  7.39it/s]evaluate test:  87%|████████▋ | 204/235 [00:27<00:04,  6.95it/s]evaluate test:  87%|████████▋ | 205/235 [00:27<00:04,  7.15it/s]evaluate test:  88%|████████▊ | 206/235 [00:27<00:03,  7.33it/s]evaluate test:  88%|████████▊ | 207/235 [00:27<00:03,  7.45it/s]evaluate test:  89%|████████▊ | 208/235 [00:27<00:03,  7.52it/s]evaluate test:  89%|████████▉ | 209/235 [00:27<00:03,  7.62it/s]evaluate test:  89%|████████▉ | 210/235 [00:27<00:03,  7.73it/s]evaluate test:  90%|████████▉ | 211/235 [00:27<00:03,  7.61it/s]evaluate test:  90%|█████████ | 212/235 [00:28<00:03,  7.43it/s]evaluate test:  91%|█████████ | 213/235 [00:28<00:03,  7.20it/s]evaluate test:  91%|█████████ | 214/235 [00:28<00:03,  6.95it/s]evaluate test:  91%|█████████▏| 215/235 [00:28<00:02,  7.23it/s]evaluate test:  92%|█████████▏| 216/235 [00:28<00:02,  7.41it/s]evaluate test:  92%|█████████▏| 217/235 [00:28<00:02,  7.57it/s]evaluate test:  93%|█████████▎| 218/235 [00:28<00:02,  7.64it/s]evaluate test:  93%|█████████▎| 219/235 [00:29<00:02,  7.82it/s]evaluate test:  94%|█████████▎| 220/235 [00:29<00:01,  7.70it/s]evaluate test:  94%|█████████▍| 221/235 [00:29<00:01,  7.65it/s]evaluate test:  94%|█████████▍| 222/235 [00:29<00:01,  7.46it/s]evaluate test:  95%|█████████▍| 223/235 [00:29<00:01,  6.94it/s]evaluate test:  95%|█████████▌| 224/235 [00:29<00:01,  6.99it/s]evaluate test:  96%|█████████▌| 225/235 [00:29<00:01,  7.33it/s]evaluate test:  96%|█████████▌| 226/235 [00:29<00:01,  7.61it/s]evaluate test:  97%|█████████▋| 227/235 [00:30<00:01,  7.81it/s]evaluate test:  97%|█████████▋| 228/235 [00:30<00:00,  7.94it/s]evaluate test:  97%|█████████▋| 229/235 [00:30<00:00,  8.04it/s]evaluate test:  98%|█████████▊| 230/235 [00:30<00:00,  7.93it/s]evaluate test:  98%|█████████▊| 231/235 [00:30<00:00,  7.79it/s]evaluate test:  99%|█████████▊| 232/235 [00:30<00:00,  7.58it/s]evaluate test:  99%|█████████▉| 233/235 [00:30<00:00,  7.09it/s]evaluate test: 100%|█████████▉| 234/235 [00:31<00:00,  7.29it/s]evaluate test: 100%|██████████| 235/235 [00:31<00:00,  7.57it/s]
08/17/2022 17:10:15 - INFO - __main__ -   ***** Test results *****
08/17/2022 17:10:15 - INFO - __main__ -     test_accuracy = 0.6072
08/17/2022 17:10:15 - INFO - __main__ -     test_f1 = 0.7109
08/17/2022 17:10:15 - INFO - __main__ -     test_precision = 0.6292
08/17/2022 17:10:15 - INFO - __main__ -     test_recall = 0.8171
08/17/2022 17:10:15 - INFO - __main__ -     test_threshold = 0.5
